A proliferação de Modelos de Linguagem de Grande Escala (LLMs) apresenta desafios significativos na deteção e mitigação de enganos digitais, uma vez que estes modelos podem emular padrões conversacionais humanos e facilitar ataques de engenharia social baseados em chat (CSE). Este estudo investiga as capacidades duplas dos LLMs como facilitadores e defensores contra ameaças CSE. Desenvolvemos um novo conjunto de dados, SEConvo, que simula cenários CSE em contextos académicos e de recrutamento, projetado para examinar como os LLMs podem ser explorados nessas situações. Os nossos resultados revelam que, embora os LLMs disponíveis no mercado gerem conteúdo CSE de alta qualidade, as suas capacidades de deteção são subótimas, levando a custos operacionais aumentados para a defesa. Em resposta, propomos o ConvoSentinel, um pipeline modular de defesa que melhora a deteção tanto ao nível da mensagem quanto da conversa, oferecendo maior adaptabilidade e rentabilidade. O módulo de recuperação aumentada no ConvoSentinel identifica intenções maliciosas comparando mensagens com uma base de dados de conversas semelhantes, melhorando a deteção CSE em todas as etapas. O nosso estudo destaca a necessidade de estratégias avançadas para aproveitar os LLMs na cibersegurança.

O avanço rápido dos LLMs inaugurou uma era de geração de diálogos semelhantes aos humanos, colocando desafios significativos na deteção e mitigação de enganos digitais. Os LLMs, com a sua capacidade de emular padrões conversacionais humanos, podem ser explorados para fins nefastos, como facilitar ataques CSE. Estas ameaças CSE transcendem os tradicionais emails de phishing e websites, impactando indivíduos e empresas igualmente, necessitando de avanços urgentes na cibersegurança. A investigação existente desenvolveu frameworks para entender ataques CSE humano-a-humano. Diversas técnicas de machine learning e deep learning foram exploradas para detetar e prevenir essas ameaças. Estudos recentes aproveitam os LLMs para simular outros tipos de ciberataques sofisticados e desenvolver defesas contra eles. No entanto, o uso indevido dos LLMs para gerar e perpetuar ataques CSE permanece largamente inexplorado, deixando-nos despreparados para enfrentar este risco emergente.

Para preencher esta lacuna, exploramos o papel duplo dos LLMs como facilitadores e defensores contra ataques CError: peer closed connection without sending complete message body (incomplete chunked read)
peer closed connection without sending complete message body (incomplete chunked read)
