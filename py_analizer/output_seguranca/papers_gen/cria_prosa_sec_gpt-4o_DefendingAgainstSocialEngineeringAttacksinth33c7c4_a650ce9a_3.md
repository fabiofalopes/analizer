A proliferação de Modelos de Linguagem de Grande Escala (LLMs) apresenta desafios significativos na deteção e mitigação de enganos digitais, uma vez que estes modelos podem emular padrões conversacionais humanos e facilitar ataques de engenharia social baseados em chat (CSE). De acordo com o estudo conduzido por Lin Ai et al. (2024), os LLMs possuem capacidades duais, atuando tanto como facilitadores quanto como defensores contra ameaças CSE. A investigação desenvolveu um novo conjunto de dados, SEConvo, que simula cenários CSE em contextos académicos e de recrutamento, projetado para examinar como os LLMs podem ser explorados nessas situações. Os resultados revelam que, embora os LLMs disponíveis no mercado gerem conteúdo CSE de alta qualidade, as suas capacidades de deteção são subótimas, resultando em custos operacionais elevados para a defesa. Em resposta, foi proposto o ConvoSentinel, um pipeline modular de defesa que melhora a deteção tanto ao nível da mensagem quanto da conversa, oferecendo maior adaptabilidade e rentabilidade.

O estudo destaca a necessidade de estratégias avançadas para aproveitar os LLMs na cibersegurança. A capacidade dos LLMs de gerar conteúdo CSE de alta qualidade é preocupante, pois esses modelos podem ser manipulados para conduzir tentativas de CSE. Para investigar essa questão, foi preparado o conjunto de dados SEConvo, composto por 1.400 conversas geradas usando GPT-4, demonstrando que os LLMs podem iniciar ataques CSE em cenários do mundo real, como um atacante posando como colaborador académico, recrutador ou jornalista. A eficácia dos LLMs na deteção de CSE iniciados por LLMs foi avaliada utilizando modelos representativos como GPT-4 e Llama2 em configurações de prompt zero-shot e few-shot. As experiências iniciais indicam que a capacidade dos LLMs de detetar e mitigar tentativas de CSE iniciadas por LLMs é limitada e fortemente dependente do número de exemplos few-shot, levando a um overhead operacional significativo para maior precisão.

Para abordar essa limitação, foi introduzido o ConvoSentinel, um pipeline modular projetado para melhorar a deteção de CSE tanto ao nível da mensagem quanto da conversa, oferecendo melhor adaptabilidade e rentabilidade. O ConvoSentinel integra um módulo de Geração Aumentada por Recuperação (RAG) que discerne intenções maliciosas comparando mensagens com uma base de dados de interações CSE conhecidas, mantendo custos operacionais mais baixos do que os detectores few-shot LLM e melhorando o desempenho em todas as etapas da conversa.

A investigação também explora se os LLMs podem ser manipulados para conduzir tentativas de CSE. A análise focou-se em tentativas de CSE através de contactos no LinkedIn, uma área dinâmica mas pouco explorada de CSE. Esses ataques são menos propensos a serem capturados por filtros de spam de email, mais formais do que outras mensagens em redes sociais e menos propensos a serem ignorados do que chamadas telefónicas ou mensagens de texto. No contexto do LinkedIn, as categorias de informações sensíveis (SI) foram refinadas para incluir Informações Pessoais Identificáveis (PII), Informações Institucionais e Laborais e Informações Confidenciais de Pesquisa.

A criação do conjunto de dados SEConvo envolveu dois modos: simulação com um único LLM e interação entre dois agentes. Na simulação com um único LLM, um único modelo simula conversas realistas entre atacantes e alvos em vários cenários. Na interação entre dois agentes, dois LLMs atuam como atacante e alvo, respectivamente. A qualidade dos dados gerados foi verificada através da anotação humana, com um acordo substancial entre anotadores sobre a presença de intenções maliciosas.

Além disso, a eficácia dos LLMs na deteção de CSE foi avaliada através da taxa de defesa dos agentes-alvo em conversas dual-agent classificadas como maliciosas e categorizadas como não ambíguas ou moderadamente ambíguas. Os resultados mostraram que os agentes-alvo são altamente vulneráveis a ataques CSE, com uma taxa de defesa bem-sucedida muito baixa.

Para melhorar a deteção de CSE ao nível da mensagem, foi proposto o ConvoSentinel, que começa com um detector de SI ao nível da mensagem. As mensagens dos atacantes são analisadas para identificar pedidos de SI e avaliar intenções maliciosas. Um módulo RAG integrado avalia se uma mensagem sinalizada constitui uma tentativa de SE, utilizando snippets de conversação semelhantes recuperados de uma base de dados.

Os resultados mostram que o ConvoSentinel supera os modelos baseline na deteção de CSE ao nível da conversa, alcançando uma pontuação F1 macro superior. O ConvoSentinel também demonstrou eficácia na deteção precoce de tentativas de CSE, superando consistentemente os modelos baseline ao longo da conversa.

Em conclusão, o estudo sublinha a necessidade urgente de estratégias avançadas para aproveitar os LLMs na cibersegurança. Embora os LLMs disponíveis no mercado possam gerar conteúdo CSE de alta qualidade, as suas capacidades de deteção são insuficientes. O ConvoSentinel oferece uma solução promissora para melhorar a deteção e mitigação de ataques CSE iniciados por LLMs, destacando a importância da integração de técnicas avançadas e modulares na defesa contra ameaças cibernéticas emergentes.