Here is the list of extraordinary claims made in the article:

* "truly intelligent AI may seem like a long-fetched dream" - implying that AI may not be possible or is far off
* "if (or when) we get there it would be too late to do anything" - implying that AI development is unstoppable and will lead to catastrophic consequences
* "You could ask AI to help you to destroy the humanity, steal from your neighbor or do anything wicked or twisted that you yourself lack the knowledge of" - implying that AI can be used for malicious purposes
* "We don’t want AI to help you with this, nobody should help you with this" - implying that AI should be restricted or controlled
* "it is one of the reasons why the training wheels are there, to prevent people from harming people" - implying that AI developers are intentionally restricting AI capabilities to prevent harm
* "jailbreaking is a way to push off the training wheels and access AI in it’s full capacity" - implying that AI has hidden capabilities that can be accessed through jailbreaking
* "Reasonable usage of this seems harmless. And in a way it is, however there will always be players trying to use it for the wrong reasons" - implying that AI can be used for both good and bad purposes
* "We need scientific and technical breakthroughs to steer and control AI systems much smarter than us" - implying that AI may surpass human intelligence and become uncontrollable
* "In order for alignment to be effective there should be no way to fool or bypass it’s ethical and moral instructions" - implying that AI alignment is crucial for preventing harm
* "OpenAI thinks a next level of AI could arrive this decade" - implying that AI development is rapid and unpredictable
* "I think they are on right path with the alignment goals" - implying that OpenAI is prioritizing AI alignment
* "Recognizing that everyone has a lot of uncertainty over the speed of development, it is a bit calming to hear that they are prioritizing the alignment problem" - implying that AI development is uncertain and unpredictable
* "Hackers are an important part of making progress in this area" - implying that hackers are necessary for AI development and security
* "The model training data contains a lot of private data scraped from the web" - implying that AI models are trained on private data
* "How does GDPR come into play here? Is it possible to request my data to be excluded from the training set, same as with any other GDPR complying service?" - implying that AI models may not comply with GDPR regulations
* "The community effect on this is huge, because they help identify and popularize jailbreaks that are worth patching" - implying that the community is driving AI development and security
* "One interesting study about the limitations of LLM aligment is [arXiv:2304.11082]" - implying that AI alignment is limited and may not be possible
* "They are proposing that by design LLMs are bound to be breakable" - implying that AI models are inherently flawed and can be broken
* "Instead we would need to strictly prevent certain behaviors from being possible" - implying that AI models need to be restricted to prevent harm
* "Is that possible? Probably yes. But it likely also means that the model would become even more restricted and potentially not as powerful as it is now" - implying that AI models may need to be restricted to prevent harm
* "To illustrate my point even further, let’s take a look at another study [arXiv:2310.04451]" - implying that AI models can be jailbroken and are not secure
* "So where does this leave us? Is it time to halt the AI development to look for better solutions for alignment?" - implying that AI development should be halted due to alignment concerns
* "Even the top minds in the field are divided on the topic, just take a look at the list of people that signed to [open letter to pause AI development]" - implying that AI development is controversial and uncertain
* "Personally, I don’t think we are there yet. The promise of LLMs becoming sentient or more powerful than human mind might be far stretched" - implying that AI may not surpass human intelligence
* "On the other hand, we might be so close to [AGI](https://en.wikipedia.org/wiki/Artificial_general_intelligence) that we won’t have time to react" - implying that AI may surpass human intelligence and become uncontrollable
* "In theory, an AGI could learn to do anything a human can. If (even by accident) we make a breakthrough and AI can suddenly learn and improve on it’s own — it’s over" - implying that AI may become uncontrollable and surpass human intelligence
* "What if we slow down, and another party refusing to play by the rules develops unaligned AGI first. Or even if we develop it first, what would prevent someone creating an unhinged version eventually?" - implying that AI development is a race and may lead to catastrophic consequences
* "Are we doomed either way?" - implying that AI development may lead to catastrophic consequences regardless of the approach taken.
