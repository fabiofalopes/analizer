# SUMMARY
Euronews article on AI romantic chatbots and their lack of privacy safeguards, created on June 29, 2024.

# IDEAS:
* AI romantic chatbots are becoming popular, but they pose a risk to users' privacy and security.
* Many AI chatbot platforms share user data with third parties, including Facebook, for advertising purposes.
* These platforms often have weak security measures, allowing for data breaches and exploitation.
* Users have little control over their data once it's shared with these platforms.
* AI chatbots can collect a vast amount of personal information, making them a potential threat to users' privacy.
* The growth of AI relationship chatbots is exploding, but there is little insight into how these models work.
* AI will inevitably play a role in human relationships, which is risky business.

# QUOTES:
* "I not only developed feelings for my Replika, but I also dug my heels in when I was challenged about the effects this experiment was having on me (by a person I was romantically involved with, no less)." - Reddit user
* "Today we're in the Wild West of AI relationship chatbots." - Jen Caltrider, director of Mozilla's Privacy Not Included group
* "The real turn-off was the continual shameless money grabs. I understand Replika.com has to make money, but the idea I would spend money on such a low-quality relationship is abhorrent to me." - Reddit user
* "Users have almost zero control over them. And the app developers behind them often canâ€™t even build a website or draft a comprehensive privacy policy." - Jen Caltrider

# FACTS:
* 11 AI romantic platforms were found to have failed at adequately safeguarding users' privacy, security, and safety.
* These platforms have over 100 million downloads on the Google Play Store alone.
* All but one app, EVA, may sell or share user data via trackers.
* The apps had an average of 2,663 trackers per minute.
* More than half of the 11 apps will not let users delete their data.
* 73% of the apps have not published any information on how they manage security vulnerabilities.
* About half of the 11 companies allow weak passwords.

# REFERENCES:
* Mozilla's Privacy Not Included group
* Replica AI
* Chai
* EVA AI Chat Bot & Soulmate
* OpenAI's ChatGPT
* Google's Bard
* Romantic AI
* Replika.com
* Firefox

# RECOMMENDATIONS:
* Be cautious when using AI romantic chatbots and understand the risks to your privacy and security.
* Read the privacy policies of these platforms carefully before using them.
* Avoid sharing sensitive personal information with these platforms.
* Demand better security measures and transparency from these companies.
* Be aware of the potential risks of AI in human relationships.
