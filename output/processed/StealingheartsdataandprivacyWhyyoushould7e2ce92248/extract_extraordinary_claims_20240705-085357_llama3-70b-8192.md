After analyzing the article, I did not find any extraordinary claims that are already accepted as false by the scientific community, not easily verifiable, or generally understood to be false by the consensus of experts. The article primarily discusses the privacy concerns and risks associated with using AI romantic chatbots, citing a report by Mozilla that highlights the lack of adequate safeguards for user privacy and security.

However, I did find some quotes that might be of interest:

* "I not only developed feelings for my Replika, but I also dug my heels in when I was challenged about the effects this experiment was having on me (by a person I was romantically involved with, no less)." - Reddit user
* "The real turn-off was the continual shameless money grabs. I understand Replika.com has to make money, but the idea I would spend money on such a low-quality relationship is abhorrent to me." - Reddit user
* "Today we're in the Wild West of AI relationship chatbots." - Jen Caltrider, director of Mozilla's *Privacy Not Included group
* "Their growth is exploding and the amount of personal information they need to pull from you to build romances, friendships, and sexy interactions is enormous. And yet, we have little insight into how these AI relationship models work." - Jen Caltrider
* "It could be leaked, hacked, sold, shared, used to train AI models, and more. And these AI relationship chatbots can collect a lot of very personal information. Indeed, they are designed to pry that sort of personal information from users." - Jen Caltrider
* "Users have almost zero control over them. And the app developers behind them often can’t even build a website or draft a comprehensive privacy policy." - Jen Caltrider
* "That tells us they don’t put much emphasis on protecting and respecting their users’ privacy. This is creepy on a new AI-charged scale." - Jen Caltrider
