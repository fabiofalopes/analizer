## SUMMARY

The study explores how large language models (LLMs) can be used to scale spear phishing attacks, highlighting their effectiveness and cost-efficiency.

## TECHNOLOGIES USED

- Large Language Models (LLMs)
- OpenAIâ€™s GPT-3.5 and GPT-4
- Prompt engineering techniques

## TARGET AUDIENCE

- Cybersecurity professionals
- AI policy makers
- General public concerned with cybersecurity

## OUTCOMES

- Demonstrated LLMs' ability to generate realistic spear phishing emails.
- Highlighted cost-effectiveness of using LLMs for phishing.
- Showed how prompt engineering can bypass LLM safeguards.
- Proposed structured access schemes and LLM-based defensive systems.

## SOCIETAL IMPACT

Positive Impacts:
- Raises awareness about the potential misuse of LLMs in cybercrime.
- Encourages development of better cybersecurity measures.

Negative Impacts:
- Demonstrates a new, scalable method for cybercriminals to exploit.
- Potential increase in successful spear phishing attacks.

## ETHICAL CONSIDERATIONS

Severity: HIGH

- Misuse of LLMs for malicious purposes.
- Ethical concerns about making such powerful tools publicly accessible.
- Risks of bypassing built-in safeguards.

## SUSTAINABILITY

Environmental:
- High computational resources required for training and running LLMs.

Economic:
- Cost-effective for cybercriminals, but potentially costly for victims and cybersecurity infrastructure.

Social:
- Increased risk of data breaches and loss of trust in digital communications.

## SUMMARY AND RATING

The project highlights significant risks associated with LLMs in spear phishing, urging better safeguards. Societal benefit: LOW. Sustainability: MEDIUM.
