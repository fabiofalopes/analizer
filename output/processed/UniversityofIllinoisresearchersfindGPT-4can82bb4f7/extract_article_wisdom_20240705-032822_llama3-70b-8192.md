# SUMMARY
University of Illinois researchers find GPT-4 can exploit real-life security flaws, created by Axios on June 29, 2024.

# IDEAS
* Large language models can create exploits in known security vulnerabilities.
* GPT-4 can write malicious scripts to exploit known vulnerabilities using publicly available data.
* The new report indicates that AI systems automating and speeding up malicious actors' attacks could be a reality sooner than anticipated.
* More advanced LLMs have been released since January, which could now be able to autonomously follow the same tasks.
* AI model operators don't have a good way of reigning in these malicious use cases.
* Allowing LLMs to digest and train on CVE data can help defenders synthesize the wave of threat alerts coming their way each day.
* Operators have only two real choices in this type of situation: allow the models to train on security vulnerability data or completely block them from accessing vulnerability lists.
* Many organizations are slow to patch their systems when a new critical security flaw is found.
* Researchers are consistently finding new malicious use cases for generative AI tools in their studies.

# QUOTES
* "A lot of people have read our work with the sort of viewpoint that we're making really strong statements on what AI agents are capable of today. But what we're really trying to show is actually the trends and capabilities." - Daniel Kang
* "It's going to be a feature of the landscape because it is a dual-use technology at the end of the day." - Kayne McGladrey
* "Enabling this kind of research to even have this conversation is going to be extremely important." - Daniel Kang

# FACTS
* GPT-4 was the only model that could exploit the vulnerabilities based on CVE data, with an 87% success rate.
* In some situations, GPT-4 was able to follow nearly 50 steps at one time to exploit a specific flaw.
* The University of Illinois team tested 10 publicly available LLM agents this year to see if they could exploit 15 so-called one-day vulnerabilities in Mitre's list of Common Vulnerabilities and Exposures (CVEs).
* Each of the vulnerabilities affects noncommercial tools.
* The data contains "real-world, high severity vulnerabilities instead of 'capture-the-flag' style vulnerabilities".
* Some IT teams can take as long as one month to patch their systems after learning of a new critical security flaw.

# REFERENCES
* Axios
* University of Illinois
* Mitre's list of Common Vulnerabilities and Exposures (CVEs)
* OpenAI
* Institute of Electrical and Electronics Engineers (IEEE)
* IBM
* The Washington Post
* Getty Images

# RECOMMENDATIONS
* Allowing LLMs to digest and train on CVE data can help defenders synthesize the wave of threat alerts coming their way each day.
* Operators should consider allowing the models to train on security vulnerability data or completely block them from accessing vulnerability lists.
* Enabling research on malicious use cases for generative AI tools is important for having conversations about the implications of this technology.
