Here is the summary of the article in Markdown format:

**ONE SENTENCE SUMMARY:**
A new AI-powered scam is using cloned voices of loved ones to trick people into sending money, and it's becoming increasingly difficult to detect and prevent.

**MAIN POINTS:**

1. The scam involves using AI to clone a person's voice, making it sound like a loved one is in distress and needs money.
2. The technology has improved significantly in recent years, making it easier to create convincing fake voices.
3. The scam is often carried out through phone calls, with the scammer demanding money and threatening harm to the loved one if it's not sent.
4. The scam has been successful in part because it's difficult to detect and prevent, and many people are unaware of its existence.
5. The Federal Trade Commission has reported that Americans lost over $2 million to impostor scams in 2022.
6. Lawmakers are working to create new regulations to combat the scam, but it's unclear how effective they will be.
7. Experts are working on developing new ways to protect consumers from voice cloning, but it's a challenging task.
8. The scam has already affected many people, including a woman who received a call from what sounded like her daughter's voice, and a couple who lost $750 to the scam.

**TAKEAWAYS:**

1. Be cautious of unexpected phone calls from loved ones, especially if they're asking for money.
2. Verify the identity of the caller before sending any money.
3. Be aware of the existence of this scam and educate others about it.
4. Consider creating a family password to verify identities in case of an emergency.
5. Law enforcement and regulators are working to combat the scam, but it's a complex and evolving issue.
