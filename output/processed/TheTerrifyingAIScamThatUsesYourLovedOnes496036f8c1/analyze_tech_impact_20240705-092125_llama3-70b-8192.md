**SUMMARY**
A new AI-powered scam uses voice cloning to trick victims into sending money, with a convincing replica of a loved one's voice claiming to be in trouble.

**TECHNOLOGIES USED**
- Artificial intelligence (AI)
- Voice cloning technology
- Large language models (e.g. ChatGPT)
- Deepfake video content
- Synthetic voices

**TARGET AUDIENCE**
- General public, particularly vulnerable individuals such as the elderly
- Families with loved ones who could be impersonated

**OUTCOMES**
- Victims are tricked into sending money to scammers
- Emotional distress and anxiety caused by the convincing replica of a loved one's voice
- Financial loss for victims who send money

**SOCIAL IMPACT**
- Erosion of trust in technology and communication systems
- Increased anxiety and fear among the general public
- Potential for widespread financial loss and emotional distress

**ETHICAL CONSIDERATIONS**
- Severity: HIGH
- Concerns around the use of AI for nefarious purposes, lack of regulation, and potential for harm to individuals and society

**SUSTAINABILITY**
- Environmental impact: LOW (digital technology)
- Economic impact: HIGH (potential for widespread financial loss)
- Social impact: HIGH (erosion of trust, emotional distress, and potential for harm to individuals and society)

**SUMMARY AND RATING**
- Overall benefit to society: LOW
- Sustainability: LOW
