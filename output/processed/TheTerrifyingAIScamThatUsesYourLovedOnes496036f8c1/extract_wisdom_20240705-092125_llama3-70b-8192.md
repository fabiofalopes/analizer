**SUMMARY**
The New Yorker article discusses a new AI scam that uses a loved one's voice to trick victims into sending money. The scam involves a caller claiming to be a family member in distress, using a cloned voice to make the call sound authentic. The article shares several stories of people who have fallen victim to this scam, including a woman named Robin and her husband Steve, who lost $750 to the scam.

**IDEAS:**

* AI technology has advanced to the point where it can clone a person's voice with ease
* The cloned voice can be used to scam people into sending money
* The scam is often used to target elderly people or those who are vulnerable
* The technology is available to anyone with an internet connection
* The scam is difficult to track and prosecute
* The use of AI in scams is becoming more prevalent
* The technology is also being used for legitimate purposes, such as voice banking for people with voice-depriving diseases
* The film industry is using AI to dub movies in different languages
* Celebrities are using AI to "loan" their voices for advertisements
* The technology is raising concerns about privacy and authentication
* Laws and regulations are struggling to keep up with the rapid advancement of AI technology
* The use of AI in scams is a growing concern for law enforcement and consumers alike

**INSIGHTS:**

* The advancement of AI technology has created new opportunities for scammers to exploit
* The use of cloned voices is making it increasingly difficult to verify the authenticity of calls
* The scam is often successful because it preys on people's emotions and vulnerabilities
* The technology is raising important questions about privacy, authentication, and regulation
* The use of AI in scams is a growing concern that requires a coordinated effort to combat

**QUOTES:**

* "I can now clone the voice of just about anybody and get them to say just about anything." - Hany Farid
* "The future is gonna be really fucking weird, kids." - Joe Rogan
* "It's simple. You take thirty or sixty seconds of a kid's voice and log in to ElevenLabs, and pretty soon Grandma's getting a call in Grandson's voice saying, 'Grandma, I'm in trouble, I've been in an accident.'" - Hany Farid
* "Shit's getting weird." - Hany Farid
* "I didn't think about it at the time that it wasn't his real voice. That's how convincing it was." - Elderly Democrat in New Hampshire

**HABITS:**

* Robin and Steve created a family password to verify authenticity in case of an emergency
* Jennifer DeStefano is now more cautious when receiving calls from unknown numbers
* RaeLee Jorgensen is more aware of the potential for scams and is taking steps to protect herself and her family

**FACTS:**

* The Federal Trade Commission reported that Americans lost over $2 million to impostor scams in 2022
* The F.T.C. has put out a voice-cloning advisory to warn consumers about the potential for scams
* ElevenLabs is a company that offers voice-cloning technology for a fee
* The technology is being used in various industries, including film and advertising
* The use of AI in scams is a growing concern for law enforcement and consumers alike

**REFERENCES:**

* ElevenLabs
* Vall-E
* The New Yorker
* The F.T.C.
* Nomorobo
* The QUIET Act
* Senate Judiciary Committee

**ONE-SENTENCE TAKEAWAY**
A new AI scam is using cloned voices to trick victims into sending money, highlighting the need for increased awareness and regulation in the rapidly advancing field of AI technology.

**RECOMMENDATIONS:**

* Be cautious when receiving calls from unknown numbers
* Verify the authenticity of calls before sending money or providing personal information
* Use strong passwords and two-factor authentication to protect online accounts
* Stay informed about the latest scams and frauds
* Support legislation that aims to regulate the use of AI technology
* Consider using voice-cloning technology for legitimate purposes, such as voice banking for people with voice-depriving diseases.
