# IDEAS
* Deepfake scams are increasingly targeting corporate executives, using AI voice clones and virtual meetings.
* Fraudsters impersonated WPP's CEO Mark Read using a fake WhatsApp account and YouTube footage in a virtual meet.
* The attempted fraud involved a voice clone of the executive and a publicly available image used as a contact display picture.
* AI voice clones have fooled banks, duped financial firms, and put cybersecurity departments on alert.
* The number of deepfake attacks in the corporate world has surged over the past year.
* Generative AI has made it possible to create realistic imitations of a person's voice using only a few minutes of audio.
* Low-cost audio deepfake technology has become widely available and far more convincing.
* Deepfake audio has targeted political candidates and crept into other less prominent targets.
* Scammers are using generative AI to mimic legitimate corporate communications and imitate executives.
* Cybersecurity departments are grappling with the boom of generative AI and its potential harms.
* Companies are pivoting resources toward generative AI while facing its potential risks.
* WPP is partnering with Nvidia to create advertisements with generative AI, touting it as a sea change in the industry.
* The rise of deepfake audio has significant implications for the future of corporate security and communication.
* AI voice clones can be used to impersonate anyone, including political candidates and corporate executives.
* The use of deepfakes in scams has become increasingly sophisticated, making it harder to detect.
* The line between legitimate and fake communications is becoming increasingly blurred.
