# IDEAS
* Generative AI makes fraud easier and cheaper to commit, challenging banks' anti-fraud efforts.
* Deepfakes incorporate self-learning systems, constantly updating to fool detection systems.
* New generative AI tools make deepfake videos, voices, and documents easily available to fraudsters.
* Democratization of nefarious software makes current anti-fraud tools less effective.
* Financial services firms are concerned about generative AI fraud accessing client accounts.
* Deepfake incidents in fintech increased 700% in 2023, with audio deepfakes particularly vulnerable.
* Business email compromises are highly vulnerable to generative AI fraud, causing substantial losses.
* Generative AI email fraud losses could total $11.5 billion by 2027 in an aggressive adoption scenario.
* Existing risk management frameworks may not be adequate to cover emerging AI technologies.
* Banks are deploying AI and machine learning tools to detect, alert, and respond to threats.
* Large language models are being used to detect signs of fraud, such as email compromises.
* Mastercard's Decision Intelligence tool predicts if a transaction is genuine by scanning a trillion data points.
* Banks should focus on coupling modern technology with human intuition to preempt fraud attacks.
* Anti-fraud teams should continually accelerate their self-learning to keep pace with fraudsters.
* Future-proofing banks against fraud requires redesigning strategies, governance, and resources.
* Collaboration within and outside the banking industry is necessary to stay ahead of generative AI fraud.
* Customers can serve as partners in helping prevent fraud losses through education and awareness.
* Regulators are focused on the promise and threats of generative AI alongside the banking industry.
* Banks should invest in hiring new talent and training current employees to spot, stop, and report AI-assisted fraud.
