Here are the INSIGHTS:

• Generative AI's self-learning system constantly updates its ability to fool computer-based detection systems, making fraud easier and cheaper.
• The democratization of nefarious software is making current anti-fraud tools less effective, challenging banks' efforts to stay ahead of fraudsters.
• Financial services firms are particularly concerned about generative AI fraud that accesses client accounts, with deepfake incidents increasing 700% in fintech in 2023.
• Business email compromises are vulnerable to generative AI, causing substantial monetary loss, with estimated losses of $11.5 billion by 2027 in an "aggressive" adoption scenario.
• Banks must couple modern technology with human intuition to determine how technologies may be used to preempt attacks by fraudsters and maintain a competitive edge.
• Anti-fraud teams should continually accelerate their self-learning to keep pace with fraudsters, requiring banks to redesign their strategies, governance, and resources.
• Collaboration within and outside the banking industry is crucial to stay ahead of generative AI fraud, requiring entities to work together and develop strategies to address liability concerns.
• Customers can serve as partners in helping prevent fraud losses, but customer relationships may be tested when determining liability for fraud losses.
• Regulators are focused on the promise and threats of generative AI, and banks should actively participate in developing new industry standards and bring in compliance early during technology development.
• Banks should invest in hiring new talent and training current employees to spot, stop, and report AI-assisted fraud, prioritizing extensive training to stay ahead of fraudsters.
