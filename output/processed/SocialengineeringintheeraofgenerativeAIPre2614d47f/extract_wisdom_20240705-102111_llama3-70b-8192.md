# SUMMARY
Article discussing the predictions for social engineering in the era of generative AI in 2024, highlighting the risks and opportunities for businesses and individuals.

# IDEAS
* Breakthroughs in large language models are driving an arms race between cybersecurity and social engineering scammers.
* Generative AI is both a curse and an opportunity for businesses, introducing new cyber risks.
* AI models are being used to create convincing social engineering attacks and generate misinformation at scale.
* Cyber criminals can create highly convincing personas and extend their reach through social media, email, and live audio or video calls.
* Technical expertise will no longer be a barrier to entry for cyber criminals.
* Custom open-source model training will advance cyber crime.
* Live deepfake scams will become a serious threat.
* Organizations and individuals must protect themselves by incorporating AI into their threat detection and mitigation processes.

# INSIGHTS
* The democratization of AI and data is making it easier for non-technical threat actors to join the fray.
* AI-created phishing content is becoming increasingly convincing and personalized.
* The gap between human and AI-generated phishing content is closing fast.
* Social engineering scammers are using AI to create intimate target profiles for highly personalized attacks.
* The development of open-source models is increasing the risk of custom and unrestricted models being used for cyber crime.

# QUOTES
* "The constant fear of missing out isn’t helping either."
* "It’s not just AI models themselves that cyber criminals are targeting."
* "The risks are less clear."
* "With that in mind, here are some of our top generative AI-driven cyber crime predictions for 2024."
* "The only viable way for infosec professionals to keep up is to incorporate AI into their threat detection and mitigation processes."

# HABITS
* Staying ahead of cyber criminals by thinking like them and using similar tools and processes.
* Training employees to detect synthetic media and defend reality against the rising tide of fakery.
* Incorporating AI into threat detection and mitigation processes.
* Using AI solutions to improve the speed, accuracy, and efficiency of security teams.

# FACTS
* 11% click-through rate for AI-generated phishing simulation email.
* 14% click-through rate for human-generated phishing email.
* 3,000% increase in deepfake fraud attempts in 2023.
* Face-swapping technology is now readily available.
* Microsoft's VALL-E can create a convincing clone of someone's voice from a three-second audio recording.
* Handwriting isn't immune from deepfakes.

# REFERENCES
* IBM's report on AI vs. human deceit
* IBM's in-depth guide to cybersecurity in the era of generative AI
* WormGPT and FraudGPT chatbots used for developing malware or carrying out hacking attacks
* CNN report on deepfake CFO scam
* Onfido's identity fraud report
* Microsoft's VALL-E AI program
* Bloomberg article on AI mimicking handwriting

# ONE-SENTENCE TAKEAWAY
Generative AI is driving an arms race between cybersecurity and social engineering scammers, requiring organizations and individuals to incorporate AI into their threat detection and mitigation processes.

# RECOMMENDATIONS
* Incorporate AI into threat detection and mitigation processes to stay ahead of cyber criminals.
* Train employees to detect synthetic media and defend reality against the rising tide of fakery.
* Use AI solutions to improve the speed, accuracy, and efficiency of security teams.
* Stay informed about the latest developments in generative AI and its applications in cyber crime.
* Develop custom and open-source models with robust safety barriers to prevent abuse.
* Use red-teaming and offensive security to think like cyber criminals and stay ahead of them.
