# SUMMARY
Summary: This article discusses the predictions for social engineering in 2024, particularly with the rise of generative AI, and how it will shape the cyber crime landscape. Created by IBM, the article highlights the potential risks and threats of generative AI in social engineering attacks.

# IDEAS
* Breakthroughs in large language models (LLMs) are driving an arms race between cybersecurity and social engineering scammers.
* Generative AI is both a curse and an opportunity for businesses, as it brings new cyber risks while also providing opportunities for creative and analytical processes.
* Cyber criminals can create highly convincing personas and extend their reach through social media, email, and live audio or video calls using generative AI.
* Technical expertise will no longer be a barrier to entry for cyber criminals, as they can use LLMs to create convincing phishing emails and malicious scripts.
* Custom open-source model training will advance cyber crime, as open-source LLMs can be customized and unleashed from arbitrary constraints.
* Live deepfake scams will become a serious threat, as deepfake videos can convincingly impersonate individuals during live conference calls.
* Organizations and individuals can protect themselves by incorporating AI into their threat detection and mitigation processes and thinking like cyber criminals.

# QUOTES
* "The constant fear of missing out isnâ€™t helping either."
* "Fakery is the new normal."
* "The only viable way for infosec professionals to keep up is to incorporate AI into their threat detection and mitigation processes."
* "The most effective way to keep ahead of cyber criminals is to think like cyber criminals."

# FACTS
* 11% of AI-generated phishing simulation emails were clicked through, compared to 14% for humans.
* There was a 3,000% increase in deepfake fraud attempts in 2023.
* Microsoft's VALL-E can create a convincing clone of someone's voice from a three-second audio recording.
* Handwriting isn't immune from deepfakes.

# REFERENCES
* IBM
* Large language models (LLMs)
* Generative AI
* ChatGPT
* Midjourney
* Stable Diffusion
* GPT4ALL
* WormGPT
* FraudGPT
* CNN
* Onfido
* Microsoft's VALL-E
* Bloomberg

# RECOMMENDATIONS
* Incorporate AI into threat detection and mitigation processes.
* Think like cyber criminals to stay ahead of them.
* Train employees to detect synthetic media.
* Use AI solutions to improve the speed, accuracy, and efficiency of security teams.
* Read IBM's in-depth guide on cybersecurity in the era of generative AI.
