# IDEAS
* Deepfake scams have looted millions of dollars from companies worldwide, and experts warn it could get worse.
* Generative AI technology has lowered the barrier of entry for cyber criminals to create deepfakes.
* The volume and sophistication of deepfake scams have expanded as AI technology continues to evolve.
* Deepfakes can be used to generate human-like text, image, and video content for illicit activities.
* Cyber criminals are using deepfakes to digitally manipulate and recreate certain individuals for fraud.
* Companies are worried about deepfakes being used to spread fake news, manipulate stock prices, and defame brands.
* Generative AI can create deepfakes based on publicly available digital information on social media and other platforms.
* Executives are limiting their online presence due to fear of deepfakes being used by cybercriminals.
* Deepfake technology has become widespread outside the corporate world, including fake pornographic images and manipulated videos.
* Deepfakes of politicians have been rampant, and some scammers have made deepfakes of individuals' family members and friends.
* Cybercrime prevention requires thoughtful analysis to develop systems, practices, and controls to defend against new technologies.
* Companies can bolster defenses to AI-powered threats through improved staff education, cybersecurity testing, and requiring code words and multiple layers of approvals for all transactions.
* The growing availability of new generative AI tools will accelerate the implementation of deepfakes by malicious actors.
* Deepfakes can be used to spread misinformation and disinformation, and can have broader implications for society.
* The cybersecurity space struggles to catch up to rapidly developing technology, making it difficult to prevent deepfake scams.
