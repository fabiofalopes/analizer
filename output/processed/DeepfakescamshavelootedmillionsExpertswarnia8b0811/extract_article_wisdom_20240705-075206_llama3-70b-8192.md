**SUMMARY**
Deepfake scams have looted millions of dollars from companies worldwide, and cybersecurity experts warn it could get worse as criminals exploit generative AI for fraud, as reported by Dylan Butts on CNBC.

**IDEAS**
* Deepfake scams have robbed companies of millions of dollars worldwide.
* Cybersecurity experts warn that the problem could get worse as generative AI technology evolves.
* The public accessibility of AI services has lowered the barrier of entry for cybercriminals.
* Deepfakes can be used to spread fake news, manipulate stock prices, and defame a company's brand.
* Generative AI is able to create deepfakes based on publicly available digital information.
* Some executives are wiping out or limiting their online presence due to fear of being used by cybercriminals.
* Cybersecurity experts recommend improved staff education, cybersecurity testing, and requiring code words and multiple layers of approvals for all transactions to defend against AI-powered threats.

**QUOTES**
* "The public accessibility of these services has lowered the barrier of entry for cyber criminals — they no longer need to have special technological skill sets." - David Fairman, chief information officer and chief security officer of APAC at Netskope.
* "That's just scratching the surface." - Jason Hogg, cybersecurity expert and executive-in-residence at Great Hill Partners.
* "The broader issues will accelerate and get worse for a period of time as cybercrime prevention requires thoughtful analysis in order to develop systems, practices, and controls to defend against new technologies." - Jason Hogg.

**FACTS**
* A Hong Kong finance worker was duped into transferring $25 million to fraudsters using deepfake technology.
* UK engineering firm Arup confirmed that it was the company involved in the case, but could not go into details due to the ongoing investigation.
* In 2019, the chief executive officer of a British energy provider reportedly transferred €220,000 to a scammer who had digitally mimicked the head of his parent company.
* Researchers at Google-owned cybersecurity company Mandiant documented instances of illicit actors using AI and deepfake technology for phishing scams, misinformation, and other illicit purposes.
* Scammers have made deepfakes of individuals' family members and friends in attempts to fool them out of money.

**REFERENCES**
* Open AI's Chat GPT
* Netskope
* Mandiant
* Great Hill Partners
* Binance
* Drexel
* Le Creuset
* Taylor Swift

**RECOMMENDATIONS**
* Improve staff education on deepfake scams and AI-powered threats.
* Conduct regular cybersecurity testing to defend against AI-powered threats.
* Require code words and multiple layers of approvals for all transactions.
* Limit online presence to prevent being used by cybercriminals.
* Develop systems, practices, and controls to defend against new technologies.
