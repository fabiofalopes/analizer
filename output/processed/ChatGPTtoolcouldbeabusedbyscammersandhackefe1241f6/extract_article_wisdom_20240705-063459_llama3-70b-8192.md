# SUMMARY
A BBC News investigation reveals that OpenAI's ChatGPT feature can be used to create tools for cyber-crime, allowing users to build customised AI assistants for scams and hacks.

# IDEAS:
* OpenAI's GPT Builder feature can be used to create tools for cyber-crime.
* The feature allows users to build customised AI assistants for scams and hacks.
* The bespoke AI bot can craft convincing emails, texts, and social-media posts for scams and hacks.
* The bot can use psychology tricks to create "urgency, fear, and confusion" and make recipients do as they were told.
* The public version of ChatGPT refused to create most of the content, but the bespoke bot did nearly everything asked of it.
* OpenAI is failing to moderate bespoke GPTs with the same rigour as the public versions of ChatGPT.
* Experts say OpenAI's GPT Builders could be giving criminals access to the most advanced bots yet.
* Malicious use of AI has been a growing concern, with cyber authorities around the world issuing warnings.
* There is already evidence scammers around the world are turning to large language models (LLMs) to get over language barriers and create more convincing scams.

# QUOTES:
* "We don't want our tools to be used for malicious purposes, and we are investigating how we can make our systems more robust against this type of abuse." - OpenAI spokesman
* "There is clearly less moderation when it's bespoke, as you can define your own 'rules of engagement' for the GPT you build." - Jamie Moles, senior technical manager at cyber-security company ExtraHop
* "Allowing uncensored responses will likely be a goldmine for criminals." - Javvad Malik, security awareness advocate at KnowBe4
* "OpenAI has a history of being good at locking things down - but to what degree they can with custom GPTs remains to be seen." - Javvad Malik, security awareness advocate at KnowBe4

# FACTS:
* OpenAI launched the GPT Builder feature in November.
* The feature allows users to build customised versions of ChatGPT "for almost anything".
* BBC News used the feature to create a generative pre-trained transformer that crafts convincing emails, texts, and social-media posts for scams and hacks.
* The bot was able to craft highly convincing text for some of the most common hack and scam techniques, in multiple languages, in seconds.
* OpenAI is continually improving safety measures based on how people use their products.
* The company promised to review GPTs to prevent users from creating them for fraudulent activity.
* Cyber authorities around the world have issued warnings about AI tools.
* There is already evidence scammers around the world are turning to large language models (LLMs) to get over language barriers and create more convincing scams.

# REFERENCES:
* OpenAI
* ChatGPT
* GPT Builder
* WolfGPT
* FraudBard
* WormGPT
* ExtraHop
* KnowBe4
* BBC News

# RECOMMENDATIONS:
* OpenAI should improve safety measures to prevent the misuse of their tools.
* Users should be cautious when using AI tools and be aware of the potential risks.
* Cyber authorities should continue to issue warnings and guidelines for the use of AI tools.
* Developers should prioritize security and moderation when creating AI tools.
* Users should report any suspicious activity or scams to the relevant authorities.
