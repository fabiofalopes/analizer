# IDEAS
* AI-backed side channel attackers can interpret remote keystrokes with 93% accuracy using sound profiles.
* Ubiquitous machine learning, microphones, and video calls present a greater threat to keyboards than ever.
* Laptops are more susceptible to having their keyboard recorded in quieter public areas.
* Uniform, non-modular keyboards have similar acoustic profiles across models, making them vulnerable.
* Combining keystroke interpretations with a hidden Markov model can correct errors and increase accuracy.
* Self-attention layers in neural networks can propagate an audio side channel attack.
* Training a deep learning model on keystroke recordings can achieve high accuracy in detecting keystrokes.
* Phone-recorded data and Zoom audio can be used to train and validate the model.
* The position of a key plays an important role in determining its audio profile.
* False-classifications tend to be only one or two keys away, making correction possible.
* Changing typing style, using randomized passwords, and adding false keystrokes can mitigate these attacks.
* Biometric tools, like fingerprint or face scanning, can be used instead of typed passwords.
* Sound-based side channel attacks on sensitive computer data are a real threat, though rarely disclosed.
* Side channel attacks themselves are a real threat, as seen in the 2013 "Dropmire" scandal.
* Machine learning and webcam mics can be used to "see" a remote screen.
* Computer sounds can be used to read PGP keys, highlighting the importance of security measures.
