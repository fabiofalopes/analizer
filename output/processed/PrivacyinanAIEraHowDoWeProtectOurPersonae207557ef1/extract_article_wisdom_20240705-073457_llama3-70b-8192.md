**SUMMARY**
A new report by Jennifer King and Caroline Meinhardt analyzes the risks of AI to privacy and offers potential solutions, including a shift to opt-in data sharing and a supply chain approach to data privacy.

**IDEAS**
* AI systems pose new challenges for privacy, including the risk of others using our data for anti-social purposes
* The scale of AI systems makes it difficult for individuals to control their personal information
* AI tools can be used for spear-phishing and identity theft
* Data such as resumes and photographs can be repurposed for training AI systems without consent
* Predictive systems can be biased, leading to civil rights implications
* Facial recognition algorithms can misidentify people, leading to false arrests
* A stronger regulatory system is needed to require opt-in data collection and deletion of misused data
* Data minimization and purpose limitation regulations are necessary but may be difficult to operationalize
* A supply chain approach to data privacy is needed to regulate AI
* Collective solutions, such as data intermediaries, are needed to give people more control over their data

**QUOTES**
* "I'm an optimist. There's certainly a lot of data that's been collected about all of us, but that doesn't mean we can't still create a much stronger regulatory system that requires users to opt in to their data being collected or forces companies to delete data when it's being misused." - Jennifer King
* "I don't think it's too late to roll things back. These default rules and practices aren't etched in stone." - Jennifer King
* "We're already seeing companies shift to this ubiquitous data collection that trains AI systems, which can have major impact across society, especially our civil rights." - Jennifer King

**FACTS**
* AI systems are data-hungry and intransparent, making it difficult for individuals to control their personal information
* Generative AI tools can memorize personal information and use it for anti-social purposes
* Predictive systems have been biased, leading to civil rights implications
* Facial recognition algorithms have misidentified people, leading to false arrests
* The California Privacy Protection Act (CPPA) provides that browsers may include a built-in opt-out signal
* A California legislator has proposed a change to the CPPA that would require all browser makers to respect third-party opt-out signals

**REFERENCES**
* Rethinking Privacy in the AI Era: Policy Provocations for a Data-Centric World (white paper)
* Apple's App Tracking Transparency (Apple ATT)
* Global Privacy Control
* California Privacy Protection Act (CPPA)
* American Data Privacy and Protection Act (ADPPA)
* General Data Protection Regulation (GDPR)
* Stanford University Institute for Human-Centered Artificial Intelligence (Stanford HAI)

**RECOMMENDATIONS**
* Implement a shift to opt-in data sharing
* Use software to make opt-in data sharing more seamless
* Implement a supply chain approach to data privacy
* Establish collective solutions, such as data intermediaries, to give people more control over their data
* Strengthen regulatory systems to require opt-in data collection and deletion of misused data
* Implement data minimization and purpose limitation regulations
