Here are the INSIGHTS:

• AI systems pose new challenges for privacy, including the risk of others using our data for anti-social purposes.
• The scale of AI systems' data collection and intransparency makes it difficult for individuals to control their personal information.
• AI tools can memorize personal information and relational data, enabling spear-phishing and identity theft.
• Predictive systems can perpetuate biases, leading to civil rights implications, such as biased hiring practices.
• Facial recognition algorithms can misidentify individuals, leading to false arrests and perpetuating systemic biases.
• A stronger regulatory system is needed to require opt-in data collection and deletion of misused data.
• The default should be that personal data is not collected unless individuals affirmatively opt-in.
• Data minimization and purpose limitation regulations are critical but require effective operationalization.
• A supply chain approach to data privacy is necessary to address issues on both the input and output sides of AI systems.
• Regulating AI requires attention to the entire data supply chain to protect privacy and avoid bias.
• Collective solutions, such as data intermediaries, are needed to give individuals more leverage over their data rights.
• Individual privacy rights are insufficient in the face of massive data collection and require collective action.
• Data intermediaries can provide a scalable solution for consumers to negotiate their data rights.
