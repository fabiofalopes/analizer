**SUMMARY**
Jennifer King, privacy and data policy fellow at Stanford University Institute for Human-Centered Artificial Intelligence, discusses the risks of AI to privacy and potential solutions in a new report.

**IDEAS**
* AI systems pose new challenges for privacy, including the risk of others using our data for anti-social purposes.
* AI tools trained with data scraped from the internet may memorize personal information about people.
* Data such as resumes or photographs shared for one purpose can be repurposed for training AI systems without our knowledge or consent.
* Predictive systems used for screening candidates can be biased, leading to civil rights implications.
* Facial recognition algorithms can misidentify people, leading to false arrests.
* The default should be that our data is not collected unless we affirmatively ask for it to be collected.
* A shift from opt-out to opt-in data sharing could be made more seamless using software.
* A supply chain approach to data privacy is necessary to regulate AI.
* The focus on individual privacy rights is too limited, and collective solutions are needed.

**INSIGHTS**
* AI systems amplify existing privacy risks, making it harder to control our personal information.
* The scale of data collection and use in AI systems requires a stronger regulatory system.
* Opt-in data collection is necessary to protect our privacy in the AI era.
* A collective approach to data privacy is necessary to give consumers more leverage.
* The data supply chain must be regulated to prevent bias and improve AI models.

**QUOTES**
* "I'm an optimist. There's certainly a lot of data that's been collected about all of us, but that doesn't mean we can't still create a much stronger regulatory system..."
* "I don't think companies need that excuse for collecting people's data."
* "I don't think it's too late to roll things back. These default rules and practices aren't etched in stone."
* "We've established the utility of the internet. I don't think companies need that excuse for collecting people's data."

**HABITS**
* Jennifer King advocates for a shift from opt-out to opt-in data sharing.
* She proposes using software to make opt-in data sharing more seamless.
* She suggests using a collective approach to data privacy to give consumers more leverage.

**FACTS**
* AI systems are so data-hungry and intransparent that we have even less control over what information about us is collected.
* Generative AI tools trained with data scraped from the internet may memorize personal information about people.
* Predictive systems used for screening candidates can be biased, leading to civil rights implications.
* Facial recognition algorithms can misidentify people, leading to false arrests.

**REFERENCES**
* Rethinking Privacy in the AI Era: Policy Provocations for a Data-Centric World (white paper)
* App Tracking Transparency (Apple)
* Global Privacy Control
* California Privacy Protection Act (CPPA)
* American Data Privacy and Protection Act (ADPPA)
* General Data Protection Regulation (GDPR)

**ONE-SENTENCE TAKEAWAY**
The report proposes a shift from opt-out to opt-in data sharing and a collective approach to data privacy to protect our personal information in the AI era.

**RECOMMENDATIONS**
* Implement opt-in data sharing to protect our personal information.
* Use software to make opt-in data sharing more seamless.
* Adopt a collective approach to data privacy to give consumers more leverage.
* Regulate the data supply chain to prevent bias and improve AI models.
* Implement data minimization and purpose limitation regulations to limit data collection.
