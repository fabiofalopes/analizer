After carefully reading the article, I did not find any extraordinary claims that are already accepted as false by the scientific community, not easily verifiable, or generally understood to be false by the consensus of experts. The article appears to be a well-researched and factual report on a study about the misuse of large language models (LLMs) for malicious purposes.

The study itself seems to be a legitimate and systematic examination of the underground market for LLMs, and the findings are presented in a neutral and objective manner. The authors provide evidence-based recommendations for building safer models and mitigating the misuse of LLMs.

Therefore, I do not have any quotes to provide as there are no extraordinary claims made in the article.
