**MAIN IDEA**
Model alignment protects against accidental harms from AI, not intentional ones, and is effective in preventing casual adversaries but not skilled ones.

**MAIN RECOMMENDATION**
To defend against catastrophic risks, look beyond model alignment and focus on defending attack surfaces that adversaries might target using unaligned models.
