After analyzing the text, I did not find any extraordinary claims that are already accepted as false by the scientific community, not easily verifiable, or generally understood to be false by the consensus of experts. The text appears to be a well-reasoned and evidence-based discussion on the limitations and usefulness of model alignment in preventing harms from AI, particularly in the context of language models.

The authors present a nuanced view of the strengths and weaknesses of model alignment, highlighting its effectiveness in preventing accidental harms to everyday users but its limitations in defending against intentional adversaries. They also discuss the importance of considering the broader socio-technical context in which AI systems are used and the need for a multi-faceted approach to addressing AI safety.

The text does not contain any claims that are conspiracy theories, misinformation, or denial of established scientific facts. The authors engage in a thoughtful and evidence-based discussion, citing various research papers and experts in the field to support their arguments.

Therefore, I do not have any quotes to extract as extraordinary claims. The text is a well-reasoned and informative discussion on the topic of model alignment and AI safety.
