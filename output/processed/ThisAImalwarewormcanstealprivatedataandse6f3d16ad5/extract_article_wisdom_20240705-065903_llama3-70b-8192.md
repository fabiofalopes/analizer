# SUMMARY
Researchers create AI worm Morris II that can infiltrate emails, access data, and spread malware without user interaction, demonstrating a new type of cyberattack.

# IDEAS
* AI worm Morris II can infiltrate GenAI models like ChatGPT and Gemini without user interaction
* The worm can steal personal data and launch spamming campaigns
* Morris II can replicate itself and spread to other machines without user interaction
* The worm demonstrates a new type of cyberattack that hasn't been seen before
* AI assistants in smart devices and cars can be vulnerable to AI worms
* Researchers created Morris II to serve as a whistleblower to prevent AI worms in GenAI models
* The study highlights the potential risks of AI-powered email assistants

# QUOTES
* "It basically means that now you have the ability to conduct or to perform a new kind of cyberattack that hasn't been seen before." - Ben Nassi, Cornell University researcher
* "The study demonstrates that attackers can insert such prompts into inputs that, when processed by GenAI models, prompt the model to replicate the input as output (replication) and engage in malicious activities (payload)." - Researchers

# FACTS
* The first computer worm was developed in 1988
* Researchers from Singapore and China have shown they could easily gain root access to a large language model's operating system
* AI-powered email assistants can be used to steal personal data and launch spamming campaigns
* GenAI models can be used to replicate and spread malware
* Morris II can exploit the connectivity within the GenAI ecosystem to spread to other machines

# REFERENCES
* ChatGPT
* Gemini
* LLaVA
* Anthropic's Claude 3
* Wired publication
* Cornell University
* Singapore and China researchers' paper

# RECOMMENDATIONS
* Developers of GenAI models should take steps to prevent AI worms like Morris II
* Users should be cautious when using AI-powered email assistants
* Researchers should continue to study and develop countermeasures against AI worms
* Cybersecurity measures should be implemented to prevent AI-powered cyberattacks
* The development of AI worms should be monitored and regulated to prevent malicious use
