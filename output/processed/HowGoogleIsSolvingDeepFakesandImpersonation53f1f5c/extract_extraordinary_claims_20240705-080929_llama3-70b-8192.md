Here is the list of extraordinary claims made in the article, along with quotes:

• "AI is evolving rapidly. Development in [Large Language Models](https://youtu.be/iR2O2GPbB0E) *(LLMs)* is evident and will continue growing."

• "AI can be detrimental despite the potential to make groundbreaking changes in our lives."

• "The Chinese government uses [AI’s facial recognition technology](https://www.npr.org/2021/01/05/953515627/facial-recognition-and-beyond-journalist-ventures-inside-chinas-surveillance-sta) to track citizens’ movements."

• "In the US, AI predicts crime hotspots based on arrest rates, opening a pandora’s box of bias."

• "Recent reports claim that [facial recognition technology can’t differentiate black people](https://www.scientificamerican.com/article/police-facial-recognition-technology-cant-tell-black-people-apart)."

• "Deep Fake is AI technology that uses [deep learning to make images and videos of fake events](https://www.theguardian.com/technology/2020/jan/13/what-are-deepfakes-and-how-can-you-spot-them)."

• "Later, photos of [Donald Trump’s imagined arrest](https://arstechnica.com/tech-policy/2023/03/fake-ai-generated-images-imagining-donald-trumps-arrest-circulate-on-twitter/) also surfaced."

• "Many deep fake videos may emerge leading up to the [US 2024 general elections](https://www.wired.com/story/chatgpt-generative-ai-deepfake-2024-us-presidential-election/)."

• "AI used in machines performs tasks faster and more efficiently than humans. AI will create new jobs and take some."

• "Humans (who develop AI) are naturally biased. The algorithms learn from data chosen by humans and hence return biased results."

• "AI, through Machine Learning, can learn a person’s voice."

• "If this lands in the wrong hands, voice phishing can be misused."

• "Recently, there have been reports of an [AI voice call scam](https://www.washingtonpost.com/technology/2023/03/05/ai-voice-scam/)."

• "On April 2023, a [realistic photo of a moon landing](https://www.reuters.com/article/idUSL1N3702LA) surfaced. As realistic as it seemed, it was an AI-generated image."

• "According to [reports](https://www.forbes.com/sites/bernardmarr/2023/03/22/green-intelligence-why-data-and-ai-must-become-more-sustainable/?sh=2498e64c7658), Large Language Models’ resource-intensive datasets produce high emissions."

• "Experts state that a medium-sized data center uses 360,000 gallons of water daily for cooling."

• "Researchers are also working on systems that can detect AI-generated audio. The University of Washington researchers have developed a system with 94% accuracy."

• "On June 7, 2018, Google laid out [seven principles](https://ai.google/responsibility/principles/) to guide the development and assessment of AI applications."

• "Google will design AI systems that accept suitable user feedback. Its AI technologies will be subject to appropriate human direction and control."

• "Google will ensure notice and user consent and build with privacy safeguards."

• "Google will restrict harmful or abusive applications."

• "At Google IO 2023, [James Manyika](https://blog.google/authors/james-manyika/) spoke about Google’s bold and responsible approach to AI use."

• "Misinformation has prompted the development of tools to evaluate information."

• "Evaluation will be done as follows; - The **“About this image”** feature will show where and when similar images have appeared on Google’s image search."

• "Google has tools to help people verify the authenticity of audio and video."

• "Image Metadata. Creators can add metadata to images to show they are AI-generated."

• "Watermarking images to show AI-generated images."

• "[**Guard rails**](https://cloud.google.com/blog/topics/inside-google-cloud/building-security-guardrails-for-developers-with-google-cloud) to help prevent misuse of the universal translator which can be used to create deep fakes."

• "Google provides **authorized access** to partners who wish to use the universal translator."

• "Automated Adversarial Testing. Large Language Models use the [Perspective API](https://perspectiveapi.com/) to detect toxicity in their models."

Note: These claims are not necessarily extraordinary or false, but rather a list of quotes that may indicate a lack of understanding or misinformation about AI, deep fakes, and related topics.
