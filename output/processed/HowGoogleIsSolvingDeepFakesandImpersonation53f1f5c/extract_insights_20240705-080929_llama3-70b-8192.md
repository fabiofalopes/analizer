Here are the INSIGHTS:

• AI development should prioritize social benefits, minimize risks, and respect cultural and social norms.
• Unfair biases in AI systems can be avoided by designing them to avoid unjust impacts on people.
• AI systems should be built and tested for safety to avoid unintended harmful results.
• AI technologies should be subject to human direction and control, and accept user feedback.
• User privacy is essential, and AI systems should ensure notice, consent, and transparency.
• AI knowledge should be shared through publishing educational materials, best practices, and research.
• Harmful or abusive AI applications should be restricted, and evaluated based on primary purpose and use.
• Responsible AI development requires adapting to prevent misinformation and misuse.
• AI systems should be designed to detect and prevent deep fakes, impersonation, and voice phishing.
• Raising awareness and educating users is crucial to prevent AI-generated voice scams and misinformation.
• Developing systems that can detect AI-generated audio and video is essential to prevent misinformation.
• AI ethics guidelines should ensure the ethical use of AI products and services.
