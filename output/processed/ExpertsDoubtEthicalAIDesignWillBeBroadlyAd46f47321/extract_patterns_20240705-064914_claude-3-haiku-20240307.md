Here are the key patterns, meta-analysis, and advice extracted from the input:

PATTERNS:

- Ethical AI is difficult to define and implement due to lack of consensus on ethical principles
- Humans are the problem - whose ethics, who decides, who cares, who enforces ethical AI?
- AI can be used for both good and ill, making standards-setting a challenge
- Further AI evolution raises new questions and complications around transparency, control, and unintended consequences
- Control of AI is concentrated in the hands of powerful companies and governments driven by profit and power motives
- Global competition, especially between China and the US, will matter more than ethical concerns
- Ethical AI is emerging but progress will be uneven across domains and cultures

META:

- Patterns drawn from 602 expert responses to a Pew Research/Elon University canvassing
- Responses covered a range of perspectives on the future of ethical AI design
- Patterns reflect common themes and concerns raised by multiple experts
- Experts have diverse backgrounds including academia, industry, government, and civil society

ANALYSIS:

The experts are deeply divided on whether ethical AI principles focused on the public good will be broadly adopted by 2030. While some see progress being made, the majority are skeptical that ethical AI will become the norm, citing challenges around defining ethics, aligning incentives, and overcoming global competition and power dynamics. The future of ethical AI remains highly uncertain.

BEST 5 PATTERNS:

1. Ethical AI is difficult to define and implement due to lack of consensus on ethical principles - Experts note there is no common agreement on what constitutes ethical behavior, making it challenging to build into AI systems.

2. Humans are the problem - whose ethics, who decides, who cares, who enforces ethical AI? - Flawed humans will be central to creating and governing ethical AI, but there are major questions around whose values get encoded and how to ensure accountability.

3. AI can be used for both good and ill, making standards-setting a challenge - The dual-use nature of AI technology makes it difficult to develop ethical guidelines that can effectively constrain harmful applications.

4. Control of AI is concentrated in the hands of powerful companies and governments driven by profit and power motives - Experts are concerned that AI development will be dominated by actors primarily interested in maximizing their own interests rather than the public good.

5. Global competition, especially between China and the US, will matter more than ethical concerns - The race for AI supremacy between nations and corporations is seen as a major obstacle to the widespread adoption of ethical AI principles.

ADVICE FOR BUILDERS:

- Recognize the difficulty of defining and implementing ethical AI - be transparent about limitations and challenges
- Engage diverse stakeholders, including ethicists and impacted communities, in AI development and deployment
- Prioritize ethical considerations alongside performance and profit motives
- Advocate for stronger governance frameworks and accountability mechanisms for AI systems
- Prepare for uneven progress - ethical AI may emerge faster in some domains than others
