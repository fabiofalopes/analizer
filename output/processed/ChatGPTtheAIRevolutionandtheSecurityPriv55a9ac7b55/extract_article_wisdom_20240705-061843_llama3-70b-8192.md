**SUMMARY**
This article discusses the implications of ChatGPT, a large language model, on security, privacy, and ethics, highlighting the potential risks and consequences of its misuse.

**IDEAS**
* ChatGPT has breached our absolute sensory threshold for AI, making us aware of its capabilities and implications.
* The AI Revolution is ongoing and cannot be stopped.
* ChatGPT can be used for malicious purposes, such as generating phishing emails and improving malware code.
* Jailbreaking and hallucination are significant security concerns.
* The use of AI can lead to large-scale disinformation and cyberattacks.
* AI developers must prioritize security and ethics in their development process.
* Regulation is necessary to prevent the misuse of AI.
* Privacy is at risk due to the collection of personal data for AI training.

**QUOTES**
* "There are three major differences between GPT3 and GPT4: longer memory, support for images, and potentially better safety and security." - Alex Polyakov
* "I doubt it is possible to create a GPT model that can’t be abused." - Mike Parkin
* "Risk should not be a showstopper, rather it should be an input to the policies, programs, and guardrails we develop." - Stephanie Aceves
* "The technology is clearly moving faster than society’s ability to build reasonable guardrails around it." - Christina Montgomery

**FACTS**
* ChatGPT-3 was made available for public use in November 2022.
* GPT-4 was announced on March 14, 2023.
* ChatGPT can process and respond to visual inputs.
* The maximum token length available in ChatGPT is 32k tokens.
* OpenAI has suffered at least one breach that exposed user information.
* The Italian data protection regulator blocked ChatGPT over concerns about personal data processing.

**REFERENCES**
* OpenAI
* WithSecure
* Sophos
* Tanium
* Netenrich
* Vulcan Cyber
* IBM
* The Cyber Collective
* Contrast Security
* Microsoft
* The Future of Life Institute
* Abnormal Security
* Rain Capital
