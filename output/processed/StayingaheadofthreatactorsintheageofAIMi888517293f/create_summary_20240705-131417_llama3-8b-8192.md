# Staying ahead of threat actors in the age of AI

## ONE SENTENCE SUMMARY:
Microsoft and OpenAI have published research on emerging threats in the age of AI, focusing on identified activity associated with known threat actors, including prompt-injections, attempted misuse of large language models (LLMs), and fraud, and have taken measures to disrupt assets and accounts associated with threat actors, improve the protection of OpenAI LLM technology and users from attack or abuse, and shape the guardrails and safety mechanisms around their models.

## MAIN POINTS:

1. The speed, scale, and sophistication of attacks have increased alongside the rapid development and adoption of AI.
2. Defenders are only beginning to recognize and apply the power of generative AI to shift the cybersecurity balance in their favor and keep ahead of adversaries.
3. Microsoft and OpenAI have published research on emerging threats in the age of AI, focusing on identified activity associated with known threat actors.
4. The research revealed behaviors consistent with attackers using AI as another productivity tool on the offensive landscape.
5. Microsoft and OpenAI have taken measures to disrupt assets and accounts associated with threat actors, improve the protection of OpenAI LLM technology and users from attack or abuse, and shape the guardrails and safety mechanisms around their models.
6. The threat ecosystem over the last several years has revealed a consistent theme of threat actors following trends in technology in parallel with their defender counterparts.
7. Cybercrime groups, nation-state threat actors, and other adversaries are exploring and testing different AI technologies as they emerge, in an attempt to understand potential value to their operations and the security controls they may need to circumvent.
8. Microsoft and OpenAI are committed to responsible AI innovation, prioritizing the safety and integrity of their technologies with respect for human rights and ethical standards.

## TAKEAWAYS:

1. AI technologies will continue to evolve and be studied by various threat actors.
2. Microsoft will continue to track threat actors and malicious activity misusing LLMs, and work with OpenAI and other partners to share intelligence, improve protections for customers, and aid the broader security community.
3. The use of LLMs by threat actors is a growing concern and requires continued monitoring and research to stay ahead of emerging threats.
4. Microsoft and OpenAI are committed to responsible AI innovation and prioritizing the safety and integrity of their technologies with respect for human rights and ethical standards.
5. The threat ecosystem is constantly evolving, and defenders must stay vigilant and adapt to new technologies and tactics used by threat actors.
