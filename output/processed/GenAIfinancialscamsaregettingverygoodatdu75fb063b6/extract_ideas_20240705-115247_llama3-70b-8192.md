# IDEAS
* Generative AI financial scammers are getting very good at duping work email using tools like ChatGPT or FraudGPT.
* Criminals can easily create realistic videos of profit and loss statements, fake IDs, false identities or even convincing deepfakes.
* One in four companies ban their employees from using generative AI, but that does little to protect against criminals.
* 65% of respondents said their organizations had been victims of attempted or actual payments fraud in 2022, with 71% compromised through email.
* Larger organizations with annual revenue of $1 billion were the most susceptible to email scams.
* Phishing emails resemble a trusted source, asking people to click on a link leading to a fake site, and spear phishing is more targeted.
* Generative AI makes it harder to tell what’s real and what’s not, and criminals can use it to create convincing phishing and spear phishing emails.
* Deepfakes involving public figures show how quickly the technology has evolved, making it easier for people to create synthetic identities.
* Large language models are trained on the internet, knowing about the company and CEO and CFO, making it easier to create realistic phishing emails.
* Automation and the mushrooming number of websites and apps handling financial transactions make the problem bigger.
* Criminals use generative AI to create credible messages quickly, then use automation to scale up, making it a numbers game.
* Financial services industry is fighting gen AI-fueled fraud with its own gen AI models, such as Mastercard's new AI model to detect scam transactions.
* Companies should have specific procedures for transferring money and verify requests through multiple channels to prevent fraud.
* A more detailed authentication process, including asking people to blink or speak their name, can help discern between real-time video and pre-recorded deepfakes.
