Here is the list of extraordinary claims made in the article:

* "Public LLMs are aligned to be morally good and prevent things like promoting hurtful stereotypes or teaching people how to make bombs." (implies that public LLMs are censored)

* "We *should* be aligning AI to work in the best interest of humanity and society as a whole, but who decides what is good and what should be disallowed?" (raises questions about the morality of AI alignment)

* "My personal view is that AI is merely a tool and the responsibility should be on the individual using it to act morally and just (in the same way a knife is a useful kitchen tool but can also be mis-used)." (implies that AI is neutral and not responsible for its actions)

* "Eric Hartford has written a brilliant article on why uncensored models should exist that goes into much more detail, please give it a read." (promotes an article that advocates for uncensored AI models)

* "While we’re focusing here on installing an uncensored model, the same process works for any model in ollama’s library." (implies that uncensored models are available and accessible)

* "Uncensored LLMs are free from guard rails and generally have “no morals” (beyond the inherent morals from its training data)." (defines uncensored LLMs as having no moral boundaries)

* "Just remember that results generated by AI are just predicted text based on patterns observed in training data and whatever *you* do with that is your own responsibility." (implies that AI is not responsible for its outputs and that users are solely responsible for their actions)

Note that these claims are not necessarily false or conspiracy theories, but rather opinions and perspectives on AI alignment and morality.
