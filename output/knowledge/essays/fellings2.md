Aqui está um segmento do ensaio sobre phishing e engenharia social na era da IA, escrito no estilo conciso e claro de Paul Graham:

Os modelos de linguagem de grande escala (LLMs) mudaram o jogo para os cibercriminosos. Antes, escrever emails de phishing convincentes e personalizados exigia tempo e habilidade. Agora, qualquer pessoa com acesso a um LLM pode gerar dezenas de mensagens persuasivas em minutos.

Testei isso eu mesmo. Usando dados públicos sobre membros do parlamento britânico, gerei centenas de emails de phishing personalizados com o GPT-3.5 da OpenAI. Cada email custou menos de um cêntimo para produzir e soava surpreendentemente autêntico.

O problema vai além dos emails. Os cibercriminosos já estão usando IA para clonar vozes e enganar as pessoas, fazendo-as acreditar que familiares estão em perigo. À medida que os sistemas generativos melhoram em vários canais de comunicação, surgirão novos vetores de ataque que nem sequer imaginamos ainda.

No futuro, os hackers poderão automatizar campanhas de engenharia social sofisticadas com pouca ou nenhuma intervenção humana. Sistemas experimentais como o Auto-GPT já demonstram o potencial dos modelos de IA para encadear prompts e perseguir objetivos abertos por conta própria.

O uso de LLMs para phishing em larga escala pode ser apenas o começo dos tipos de cibercrimes que a IA permitirá. Precisamos estar preparados para um mundo onde os ataques de engenharia social se tornarão cada vez mais convincentes e difíceis de detetar.
