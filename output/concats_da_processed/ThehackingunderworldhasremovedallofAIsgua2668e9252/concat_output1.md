### analyze_incident_20240705-022457_llama3-70b-8192
---
Here is the extracted information in the specified format:

**Attack Date:** Not specified (multiple incidents mentioned)

**Summary:** Cybercriminals are using AI to execute highly targeted attacks at scale, causing people to unwittingly send money and sensitive information or simply open themselves up to theft.

**Key Details:**

* **Attack Type:** Social engineering, business email compromise (BEC), brand impersonation, malvertising, polymorphic malware
* **Vulnerable Component:** Email systems, social media, Google ads
* **Attacker Information:**
	+ **Name/Organization:** Not specified (underground cybercrime community)
	+ **Country of Origin:** Not specified
* **Target Information:**
	+ **Name:** Various individuals and organizations
	+ **Country:** Not specified
	+ **Size:** Not specified
	+ **Industry:** Not specified
* **Incident Details:**
	+ **CVE's:** Not specified
	+ **Accounts Compromised:** Not specified
	+ **Business Impact:** Financial loss, theft of sensitive information, operational disruption
	+ **Impact Explanation:** Cybercriminals are using AI to create highly convincing scams, leading to financial loss and theft of sensitive information.
	+ **Root Cause:** Lack of guardrails in the AI frontier, allowing cybercriminals to use AI for malicious purposes

**Analysis & Recommendations:**

* **MITRE ATT&CK Analysis:** Not specified
* **Atomic Red Team Atomics:** Not specified
* **Remediation:**
	+ **Recommendation:** Use AI to understand the sentiment of messages, automate email security, and prioritize QR code detection.
	+ **Action Plan:** Implement AI-powered email security, educate users on how to identify scams, and take a risk-based approach to cybersecurity.
* **Lessons Learned:** Cybercrime is a business, and public education is key to preventing threats from completing their mission. Defenders must stay ahead of cybercriminals by using AI to detect and expose scams.
---
### extract_wisdom_20240705-022457_llama3-70b-8192
---
# SUMMARY
Cybercrime underworld has removed all guardrails on AI frontier, using AI to execute highly targeted attacks at scale, causing people to unwittingly send money and sensitive information, according to experts from McAfee, Perception Point, and Mimecast.

# IDEAS
* Cybercriminals are using AI to execute highly targeted attacks at scale.
* AI-generated email scams are becoming increasingly sophisticated.
* Business email compromise (BEC) attacks grew by 1760% in 2023.
* Generative AI tools are being used to create polymorphic malware at scale.
* Cybercriminals can rent large language models to formulate language for scams.
* AI-generated emails can imitate the writing style of a target.
* Brand impersonation instances consisted of organizations' own brands in 55% of cases.
* Malvertising is a technique used to plant malicious ads on Google.
* Cybercriminals are using AI to create deepfakes to impersonate individuals.
* AI-detection tools are being developed to combat deepfakes.
* Quishing (phishing using malicious QR codes) accounted for 2% of all threats in 2023.
* Cybercrime is a business, and public education is key to preventing threats.
* Defenders can use AI to understand the sentiment of messages and automate defense.
* Cybersecurity experts remain optimistic despite ongoing threats.

# INSIGHTS
* The efficiency promise of AI is not reserved for well-meaning workers, but also benefits cybercriminals.
* Cybercrime has removed all guardrails on the AI frontier, allowing for highly targeted attacks.
* AI-generated email scams are becoming increasingly sophisticated and difficult to detect.
* Cybersecurity experts must adapt to new threats and technologies to stay ahead of cybercriminals.
* Public education is critical in preventing cybercrime, as individuals must recalibrate their trust in what they see, hear, and read.
* Cybercrime is a business, and defenders must think like businesses to stay ahead.

# QUOTES
* "The cybercrime ecosystem has removed all of the guardrails." - Steve Grobman, McAfee
* "You have large language models that cyber criminals can rent." - Steve Grobman, McAfee
* "We know the organization from the inside." - Tal Zamir, Perception Point
* "It's important to think of cybercrime as being a business." - Steve Grobman, McAfee

# HABITS
* Ask questions like "Does this make sense?" and "Is the deal too good to be true?" to validate information.
* Validate information on a credible news source or through a separate, trustworthy individual.
* Take a risk-based approach to cybersecurity by identifying valuable assets and potential threats.
* Keep one eye focused on current threats and another on future threats.

# FACTS
* Business email compromise (BEC) attacks grew by 1760% in 2023.
* 55% of brand impersonation instances consisted of organizations' own brands in 2023.
* Quishing (phishing using malicious QR codes) accounted for 2% of all threats in 2023.
* Cybercrime underworld has removed all guardrails on AI frontier.

# REFERENCES
* Perception Point's latest annual cybersecurity trends report
* Project Mockingbird, an AI-detection tool developed by McAfee
* Mimecast, a communication and collaboration security firm
* McAfee, a cybersecurity firm
* Perception Point, a cyber threat protector

# ONE-SENTENCE TAKEAWAY
Cybercriminals are using AI to execute highly targeted attacks at scale, and defenders must adapt to new threats and technologies to stay ahead.

# RECOMMENDATIONS
* Use AI to understand the sentiment of messages and automate defense.
* Take a risk-based approach to cybersecurity by identifying valuable assets and potential threats.
* Keep one eye focused on current threats and another on future threats.
* Educate individuals on how to validate information and avoid scams.
* Develop AI-detection tools to combat deepfakes and other AI-generated threats.
* Prioritize QR code detection to combat quishing.
---
### analyze_claims_20240705-022457_llama3-70b-8192
---
**ARGUMENT SUMMARY:** The article argues that the hacking underworld has removed all guardrails on AI, enabling cybercriminals to use AI to execute highly targeted attacks at scale, causing people to unwittingly send money and sensitive information.

**TRUTH CLAIMS:**

**CLAIM:** Cybercriminals are using AI to execute highly targeted attacks at scale.

**CLAIM SUPPORT EVIDENCE:**

* According to Perception Point's latest annual cybersecurity trends report, business email compromise (BEC) grew from 1% of all threats in 2022 to 18.6% in 2023, a growth rate of 1760%. (Source: Perception Point report)
* Steve Grobman, senior vice president and chief technology officer at McAfee, stated that cybercriminals can rent large language models to eliminate grammatical errors and imitate writing styles. (Source: Interview with Steve Grobman)

**CLAIM REFUTATION EVIDENCE:** None provided.

**LOGICAL FALLACIES:** None identified.

**CLAIM RATING:** B (High)

**LABELS:** Informative, Technical, Cybersecurity-related

**CLAIM:** Generative AI is enhancing and scaling social engineering attacks.

**CLAIM SUPPORT EVIDENCE:**

* Tal Zamir, chief technology officer at Perception Point, discussed how criminals can create polymorphic malware at scale using AI and automation. (Source: Interview with Tal Zamir)
* The article provides examples of AI-generated email scams, deepfakes, and malvertising. (Source: Article)

**CLAIM REFUTATION EVIDENCE:** None provided.

**LOGICAL FALLACIES:** None identified.

**CLAIM RATING:** B (High)

**LABELS:** Informative, Technical, Cybersecurity-related

**CLAIM:** Defenders can use AI to understand the sentiment of messages and automate the process for maximum effectiveness.

**CLAIM SUPPORT EVIDENCE:**

* Kiri Addison, senior manager for product management at Mimecast, stated that defenders can use AI to understand the sentiment of messages beyond flagging specific keywords. (Source: Interview with Kiri Addison)
* The article mentions that defenders can automate the process for maximum effectiveness. (Source: Article)

**CLAIM REFUTATION EVIDENCE:** None provided.

**LOGICAL FALLACIES:** None identified.

**CLAIM RATING:** B (High)

**LABELS:** Informative, Technical, Cybersecurity-related

**OVERALL SCORE:**

LOWEST CLAIM SCORE: B (High)
HIGHEST CLAIM SCORE: B (High)
AVERAGE CLAIM SCORE: B (High)

**OVERALL ANALYSIS:** The article provides a well-informed and balanced view of the role of AI in cybercrime, highlighting both the threats and the opportunities for defenders. The evidence provided is credible and verifiable, and the claims are well-supported. The article's tone is informative and technical, making it a valuable resource for those interested in cybersecurity.
---
### extract_ideas_20240705-022457_llama3-70b-8192
---
# IDEAS
* Cybercriminals use AI to execute highly targeted attacks at scale, causing financial losses.
* AI-generated deepfakes can impersonate company executives, leading to large financial transfers.
* Business email compromise attacks grew by 1760% in 2023, propelled by generative AI tools.
* Cybercriminals rent large language models to formulate language for scams.
* AI-generated emails can eliminate grammatical errors and imitate writing styles.
* Brand impersonation attacks consist of organizations' own brands, often through social media or email.
* Malvertising involves planting malicious ads on Google to impersonate actual sites.
* AI can create polymorphic malware at scale, making it harder to detect.
* Cybercriminals use AI for vulnerability research to abuse computers.
* Defenders can use AI to understand message sentiment beyond flagging keywords.
* AI can automate email security processes for maximum effectiveness.
* AI-detection tools can detect and expose AI-altered audio within video.
* Public education is critical in preventing cyber threats from completing their mission.
* Individuals should ask questions to validate information before taking action.
* Organizations should take a risk-based approach to cybersecurity, focusing on valuable assets.
* Cybercrime is a business, and both defenders and attackers are using AI to be more productive.
---
### extract_main_idea_20240705-022457_llama3-70b-8192
---
# MAIN IDEA
Cybercriminals are leveraging AI to execute highly targeted attacks at scale, removing guardrails and causing unsuspecting victims to fall prey.

# MAIN RECOMMENDATION
To combat AI-driven cybercrime, individuals and organizations must recalibrate their trust in digital information and adopt proactive measures, such as risk-based approaches and public education.
---
### analyze_tech_impact_20240705-022457_llama3-70b-8192
---
SUMMARY
The hacking underworld has removed all guardrails on AI, using it to execute highly targeted attacks at scale, causing people to unwittingly send money and sensitive information.

TECHNOLOGIES USED
- Artificial intelligence (AI)
- Generative AI tools
- Large language models
- Deepfakes
- Polymorphic malware
- Automation
- Malvertising
- QR code detection
- AI-detection tools

TARGET AUDIENCE
- General public
- Businesses
- IT firms
- Cybersecurity experts
- Individuals using digital resources

OUTCOMES
- Highly targeted attacks at scale
- Increased efficiency in cybercrime
- Growth of business email compromise (BEC) attacks
- Rise of brand impersonation instances
- Increased use of malvertising
- Creation of polymorphic malware at scale
- Development of AI-detection tools

SOCIAL IMPACT
- Increased risk of financial loss and identity theft
- Erosion of trust in digital communications
- Potential for widespread harm to individuals and businesses
- Need for public education and awareness on cybersecurity

ETHICAL CONSIDERATIONS
- Severity: HIGH
- Concerns around the use of AI for malicious purposes
- Potential for AI to exacerbate existing social and economic inequalities

SUSTAINABILITY
- Environmental: NEUTRAL
- Economic: NEGATIVE (potential for financial loss and harm to businesses)
- Social: NEGATIVE (erosion of trust in digital communications and potential for widespread harm)

SUMMARY and RATING
The hacking underworld's removal of AI guardrails has significant negative implications for society, with a HIGH severity of ethical concerns and a NEGATIVE sustainability rating.
---
### extract_article_wisdom_20240705-022457_llama3-70b-8192
---
# SUMMARY
The article discusses how cybercriminals are using AI to execute highly targeted attacks at scale, causing people to unwittingly send money and sensitive information. Created by CNBC, the article highlights the growth of business email compromise (BEC) attacks and the use of generative AI tools to eliminate grammatical errors and imitate writing styles.

# IDEAS:
* Cybercriminals are using AI to execute highly targeted attacks at scale.
* Business email compromise (BEC) attacks grew from 1% to 18.6% of all threats in 2023.
* Generative AI tools are being used to eliminate grammatical errors and imitate writing styles.
* Cybercriminals can rent large language models to formulate language for scams.
* AI is being used to create polymorphic malware at scale.
* Defenders can use AI to understand the sentiment of messages and automate the process for maximum effectiveness.
* Cybercrime is a business, and public education is key to preventing threats.
* Individuals should ask questions like "Does this make sense?" and "Can I validate it on a credible news source?" to prevent attacks.
* Organizations should take a risk-based approach to cybersecurity.

# QUOTES:
* "The cybercrime ecosystem has removed all of the guardrails." - Steve Grobman, senior vice president and chief technology officer at McAfee.
* "We have made it such that we can live our lives and fully take advantage of the digital world that we live in, even with the cybercriminal elements at full play, largely because the cyber defense industry is able to play an effective cat-and-mouse game." - Steve Grobman.
* "You can generate these really great emails, but we can still stop them from getting to the user’s inbox so they never have to even see them." - Kiri Addison, senior manager for product management at Mimecast.
* "When you’re working in the world of AI, things are a lot less deterministic." - Steve Grobman.
* "Defenders have an advantage that attackers just cannot have. We know the organization from the inside." - Tal Zamir, chief technology officer at Perception Point.
* "It’s important to think of cybercrime as being a business." - Steve Grobman.

# FACTS:
* A Hong Kong IT firm worker transferred over $25 million to a criminal after being duped by a deepfake video call.
* A faux Taylor Swift was used to scam Swifties into buying Le Creuset cookware.
* BEC attacks grew by 1760% from 2022 to 2023.
* More than half of all brand impersonation instances consisted of organizations' own brands in 2023.
* Quishing (phishing using malicious QR codes) accounted for 2% of all threats in 2023.
* McAfee unveiled Project Mockingbird, an AI-detection tool that can detect and expose AI-altered audio within video.

# REFERENCES:
* Perception Point's latest annual cybersecurity trends report
* Project Mockingbird by McAfee
* ChatGPT
* Le Creuset cookware
* Taylor Swift
* Mimecast
* McAfee
* Perception Point

# RECOMMENDATIONS:
* Take a risk-based approach to cybersecurity.
* Ask questions like "Does this make sense?" and "Can I validate it on a credible news source?" to prevent attacks.
* Keep one eye focused on current threats and another on future threats.
* Show real examples of attacks to put things into context.
* Use AI to understand the sentiment of messages and automate the process for maximum effectiveness.
* Defend against a wider swath of problems by feeding data into existing models or generating new data sets using AI.
---
### create_threat_scenarios_20240705-022457_llama3-8b-8192
---
Here is the output based on the input:

**THREAT SCENARIOS**

* Cybercriminals using AI to execute highly targeted attacks at scale, causing people to unwittingly send money and sensitive information or simply open themselves up to theft
* Deepfakes used to impersonate company executives or celebrities to scam individuals
* Believable emails, social media posts, and advertisements with perfect grammar from accounts that look and feel like the real thing
* Brand impersonation through account takeovers on social media or email
* Malvertising, or planting a malicious ad on Google that seeks to impersonate and override visits to the actual site the fake ad copies
* Polymorphic malware created at scale using AI and automation
* Vulnerability research used to look for ways to abuse computers and make malware more dangerous
* QR code detection and quishing (phishing using malicious QR codes)

**THREAT MODEL ANALYSIS**

* Cybercriminals are using AI to enhance and scale social engineering attacks, making it harder for individuals to detect and prevent them
* AI-generated emails and messages are becoming increasingly sophisticated, making it harder to detect and prevent attacks
* Cybercriminals are using AI to create polymorphic malware and vulnerability research to make malware more dangerous
* AI is also being used to detect and prevent attacks, but it is a cat-and-mouse game between defenders and attackers

**RECOMMENDED CONTROLS**

* Use AI to understand the sentiment of messages beyond flagging specific keywords and automate the process for maximum effectiveness
* Defend against a wider swath of problems by feeding data into existing models or generating new data sets using AI
* Use AI-detection tools to detect and expose AI-altered audio within video
* Prioritize QR code detection as soon as one arrives on a device
* Take a risk-based approach to cybersecurity, asking questions like: What do you have of value? What are your assets? Why might an attacker target you?

**NARRATIVE ANALYSIS**

* The hacking underworld has removed all of the guardrails on the AI frontier, making it easier for cybercriminals to use AI to execute highly targeted attacks at scale
* Cybercriminals are using AI to create sophisticated emails and messages that are hard to detect and prevent
* Defenders are also using AI to detect and prevent attacks, but it is a cat-and-mouse game between defenders and attackers
* Public education is a proactive method for preventing threats from completing their mission, and individuals and organizations should take steps to prevent attacks and stay ahead of cybercriminals

**CONCLUSION**

* The use of AI in cybercrime is a growing concern, and individuals and organizations must take steps to prevent attacks and stay ahead of cybercriminals.
---
### extract_extraordinary_claims_20240705-022457_llama3-70b-8192
---
After analyzing the article, I did not find any extraordinary claims that are already accepted as false by the scientific community, not easily verifiable, or generally understood to be false by the consensus of experts. The article appears to be a factual report on the use of artificial intelligence in cybercrime and cybersecurity.

However, I can provide a list of quotes that discuss the use of AI in cybercrime and cybersecurity:

* "The cybercrime ecosystem has removed all of the guardrails." - Steve Grobman, senior vice president and chief technology officer at McAfee
* "You have large language models that cyber criminals can rent." - Steve Grobman, senior vice president and chief technology officer at McAfee
* "The outputs are impactful enough to eliminate grammatical errors and even imitate the writing style of a target." - Article
* "Cybercriminals can do this through account takeovers on social media or email." - Article
* "Then there’s a technique called malvertising, or planting a malicious ad on Google that seeks to impersonate and override visits to the actual site the fake ad copies." - Article
* "Criminals can now create polymorphic malware (or malware with many variations) at scale using AI and automation." - Tal Zamir, chief technology officer at Perception Point
* "We have made it such that we can live our lives and fully take advantage of the digital world that we live in, even with the cybercriminal elements at full play, largely because the cyber defense industry is able to play an effective cat-and-mouse game." - Steve Grobman, senior vice president and chief technology officer at McAfee
* "You can generate these really great emails, but we can still stop them from getting to the user’s inbox so they never have to even see them." - Kiri Addison, senior manager for product management at Mimecast
* "When you’re working in the world of AI, things are a lot less deterministic." - Steve Grobman, senior vice president and chief technology officer at McAfee
* "A lot of traditional security systems are not equipped to detect that QR code and follow up on it." - Article
* "Cybercrime is a business." - Steve Grobman, senior vice president and chief technology officer at McAfee
* "Defenders have an advantage that attackers just cannot have." - Tal Zamir, chief technology officer at Perception Point
* "We know the organization from the inside." - Tal Zamir, chief technology officer at Perception Point
---
### extract_patterns_20240705-022457_llama3-70b-8192
---
# PATTERNS

* Cybercriminals are using AI to execute highly targeted attacks at scale, causing people to unwittingly send money and sensitive information.
* AI-generated email scams are on the rise, with a growth rate of 1760% in 2023.
* Business email compromise (BEC) attacks are becoming more prevalent, with 18.6% of all threats in 2023.
* Cybercriminals are using services in the underground cybercrime community to rent large language models.
* AI is enhancing and scaling social engineering attacks, including brand impersonation and malvertising.
* Polymorphic malware is being created at scale using AI and automation.
* Cybercriminals are using AI to impersonate targets, including CEOs and celebrities.
* Defenders are using AI to understand the sentiment of messages and automate the detection process.
* AI-detection tools are being developed to combat deepfakes and other AI-altered media.
* Public education is key to preventing threats from completing their mission.
* Cybercrime is a business, and both defenders and attackers are using AI to be more productive and effective.

# META

* The article highlights the growing threat of AI-generated email scams and social engineering attacks.
* The use of large language models by cybercriminals is a key factor in the growth of these attacks.
* Defenders are using AI to combat these threats, including understanding sentiment and automating detection.
* Public education is crucial in preventing these threats from succeeding.
* Cybercrime is a business, and both sides are using AI to gain an advantage.

# ANALYSIS

Cybercriminals are leveraging AI to launch highly targeted and sophisticated attacks, including email scams and social engineering tactics, while defenders are using AI to combat these threats and stay one step ahead.

# BEST 5

* AI-generated email scams are on the rise, with a growth rate of 1760% in 2023.
* Cybercriminals are using services in the underground cybercrime community to rent large language models.
* AI is enhancing and scaling social engineering attacks, including brand impersonation and malvertising.
* Defenders are using AI to understand the sentiment of messages and automate the detection process.
* Cybercrime is a business, and both defenders and attackers are using AI to be more productive and effective.

# ADVICE FOR BUILDERS

* Implement AI-powered email security solutions to combat email scams.
* Educate users on how to identify and avoid social engineering attacks.
* Use AI to detect and prevent brand impersonation and malvertising.
* Stay ahead of emerging threats by investing in AI-powered cybersecurity solutions.
* Prioritize public education and awareness to prevent threats from succeeding.
---
### create_summary_20240705-022457_llama3-70b-8192
---
# ONE SENTENCE SUMMARY:
Cybercriminals are leveraging AI to execute highly targeted attacks at scale, causing people to unwittingly send money and sensitive information.

# MAIN POINTS:

1. Cybercriminals are using AI to execute highly targeted attacks at scale.
2. AI-generated email scams are becoming increasingly sophisticated and difficult to detect.
3. Business email compromise (BEC) attacks grew from 1% to 18.6% of all threats in 2023.
4. Cybercriminals can rent large language models to eliminate grammatical errors and imitate writing styles.
5. Brand impersonation instances consisted of organizations' own brands in 55% of cases in 2023.
6. Malvertising and polymorphic malware are becoming more prevalent due to AI and automation.
7. Defenders can use AI to understand message sentiment and automate detection processes.
8. AI-detection tools are being developed to combat deepfakes and other AI-altered content.
9. Public education is critical in preventing threats from completing their mission.
10. Cybercrime is a business, and both defenders and attackers are leveraging AI to gain an advantage.

# TAKEAWAYS:

1. AI is being used to scale and enhance social engineering attacks, making them more convincing and dangerous.
2. Defenders must adapt and use AI to stay ahead of cybercriminals in the cat-and-mouse game.
3. Public awareness and education are crucial in preventing threats from succeeding.
4. Cybercrime is a business, and understanding this can help organizations take a more proactive approach to cybersecurity.
5. AI-detection tools and risk-based approaches can help combat emerging threats like deepfakes and quishing.
---
### extract_insights_20240705-022457_llama3-70b-8192
---
Here are the INSIGHTS:

• Cybercriminals leverage AI to execute highly targeted attacks at scale, causing unwitting victims to send money and sensitive information.
• The efficiency promise of AI is not reserved for well-meaning workers, but also benefits underground operators to the detriment of unknowing victims.
• AI-generated email scams are being stopped by defenders who use AI to understand message sentiment and automate detection processes.
• Cybercrime is a business, and criminals are using AI to be more productive and effective in their attacks.
• Defenders have an advantage over attackers, as they know the organization from the inside and can play an effective cat-and-mouse game.
• Public education is key to preventing threats from completing their mission, and individuals must recalibrate their trust in what they see, hear, and read.
• AI detection is like weather forecasting, and things are less deterministic in the world of AI.
• Cybercriminals can create polymorphic malware at scale using AI and automation, making it more dangerous.
• Brand impersonation is a growing threat, with over half of instances consisting of organizations' own brands in 2023.
• Generative AI is enhancing and scaling social engineering attacks, but also gives defenders a leg up in the cat-and-mouse game.
• Cybersecurity experts remain optimistic, as defenders can use AI to understand message sentiment and automate detection processes.
---
### summarize_20240705-022457_llama3-70b-8192
---
# ONE SENTENCE SUMMARY:
Cybercriminals are leveraging AI to execute highly targeted attacks at scale, causing people to unwittingly send money and sensitive information.

# MAIN POINTS:

1. Cybercriminals are using AI to impersonate individuals and companies, leading to large-scale financial losses.
2. Business email compromise (BEC) attacks grew from 1% to 18.6% of all threats in 2023, propelled by generative AI tools.
3. Cybercriminals can rent large language models to create impactful and grammatically correct scams.
4. Brand impersonation instances increased, with 55% of cases involving organizations' own brands in 2023.
5. Malvertising and polymorphic malware are on the rise, making it difficult for defenders to keep up.
6. AI-generated email scams can be stopped using AI-powered detection tools that understand message sentiment.
7. Defenders can use AI to automate the detection process and defend against a wider range of problems.
8. Public education is key to preventing threats from completing their mission.
9. Cybercrime is a business, and both attackers and defenders are leveraging AI to gain an advantage.
10. Defenders have an advantage in knowing the organization from the inside, allowing them to stay one step ahead of attackers.

# TAKEAWAYS:

1. Cybercriminals are using AI to create highly targeted and sophisticated attacks.
2. AI-powered detection tools can help stop email scams and other cyber threats.
3. Public education and awareness are crucial in preventing cybercrime.
4. Cybercrime is a business, and both attackers and defenders are leveraging AI to gain an advantage.
5. Defenders have an advantage in knowing the organization from the inside, allowing them to stay one step ahead of attackers.
---
