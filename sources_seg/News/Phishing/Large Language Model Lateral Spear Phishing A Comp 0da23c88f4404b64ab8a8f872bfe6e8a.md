# Large Language Model Lateral Spear Phishing: A Comparative Study in Large-Scale Organizational Settings

Created: June 29, 2024 5:20 PM
URL: https://arxiv.org/html/2401.09727v1

Department of Information Systems

and Cyber Security

University of Texas at San Antonio   Athanasios Galiopoulos  Department of Information Systems

and Cyber Security

University of Texas at San Antonio   Emet Bethany  Department of Computer Science

University of Texas at San Antonio   Mohammad Bahrami Karkevandi  Department of Computer Science

University of Texas at San Antonio   Nishant Vishwamitra  Department of Information Systems

and Cyber Security

University of Texas at San Antonio   Peyman Najafirad  Department of Computer Science

University of Texas at San Antonio

Abstract

The critical threat of phishing emails has been further exacerbated by the potential of LLMs to generate highly targeted, personalized, and automated spear phishing attacks. Two critical problems concerning LLM-facilitated phishing require further investigation: 1) Existing studies on lateral phishing lack specific examination of LLM integration for large-scale attacks targeting the entire organization, and 2) Current anti-phishing infrastructure, despite its extensive development, lacks the capability to prevent LLM-generated attacks, potentially impacting both employees and IT security incident management. However, the execution of such investigative studies necessitates a real-world environment, one that functions during regular business operations and mirrors the complexity of a large organizational infrastructure. This setting must also offer the flexibility required to facilitate a diverse array of experimental conditions, particularly the incorporation of phishing emails crafted by LLMs. This study is a pioneering exploration into the use of Large Language Models (LLMs) for the creation of targeted lateral phishing emails, targeting a large tier 1 university’s operation and workforce of approximately 9,000 individuals over an 11-month period. It also evaluates the capability of email filtering infrastructure to detect such LLM-generated phishing attempts, providing insights into their effectiveness and identifying potential areas for improvement. Based on our findings, we propose machine learning-based detection techniques for such emails to detect LLM-generated phishing emails that were missed by the existing infrastructure, with an F1-score of 98.96. Our findings also highlight the urgent need for integrating existing anti-phishing infrastructure with LLM-generated phishing email detection methods and point out the need for updated organizational policies towards mitigating LLM driven phishing threats.

## 1 Introduction

The rapid advancement of internet technologies has significantly heightened security concerns, especially in the realm of phishing, a critical form of social engineering that deceitfully extracts sensitive information [[1](https://arxiv.org/html/2401.09727v1/#bib.bib1)], [[2](https://arxiv.org/html/2401.09727v1/#bib.bib2)], [[3](https://arxiv.org/html/2401.09727v1/#bib.bib3)], [[4](https://arxiv.org/html/2401.09727v1/#bib.bib4)]. Attackers masquerade as legitimate entities to gain unauthorized access to accounts and acquire confidential data [[5](https://arxiv.org/html/2401.09727v1/#bib.bib5)]. The education sector, in particular, has been heavily targeted, experiencing a 576% increase in phishing attacks from 2021 to 2022 [[6](https://arxiv.org/html/2401.09727v1/#bib.bib6)]. Lateral spear phishing, which exploits both technical and human vulnerabilities by crafting personalized communications, has become a sophisticated and deceptive attack method [[7](https://arxiv.org/html/2401.09727v1/#bib.bib7)]. This landscape is further complicated by the emergence of Large Language Models (LLMs) like OpenAI’s ChatGPT, which have shown remarkable capabilities in generating human-like text [[8](https://arxiv.org/html/2401.09727v1/#bib.bib8)], [[9](https://arxiv.org/html/2401.09727v1/#bib.bib9)], [[10](https://arxiv.org/html/2401.09727v1/#bib.bib10)]. These developments transform traditional phishing tactics, making them more nuanced and context-aware. Cisco Systems Inc. has highlighted the increased difficulty in detecting phishing attempts due to AI, urging the adoption of new defenses [[11](https://arxiv.org/html/2401.09727v1/#bib.bib11)]. Additionally, the use of AI in phishing has been noted to enhance the frequency and sophistication of social engineering attacks [[12](https://arxiv.org/html/2401.09727v1/#bib.bib12)]. In spearphishing, the advanced capabilities of LLMs to tailor messages to individual targets could significantly increase the threats’ sophistication and effectiveness [[13](https://arxiv.org/html/2401.09727v1/#bib.bib13)].

This escalating threat landscape, particularly with the involvement of LLMs in phishing, necessitates innovative studies to understand this threat and the exploration of novel cybersecurity defenses. There are two main problems regarding this new threat. First, existing studies on lateral phishing attacks do not investigate the integration of LLMs for large-scale attacks targeting the entire organizations. Previous works that analyze phishing attacks at scale, provide valuable insight into the tactics and techniques as well as mitigation strategies towards phishing threats [[14](https://arxiv.org/html/2401.09727v1/#bib.bib14), [15](https://arxiv.org/html/2401.09727v1/#bib.bib15), [16](https://arxiv.org/html/2401.09727v1/#bib.bib16)], but do not consider the role that LLMs could play in this threat. However, conducting such studies demands a real-world environment that is representative of a large-scale organizational structure. Second, existing anti-phishing infrastructure lack the capability to prevent LLM-generated attacks, potentially impacting both employees and IT operations support and incident management. Traditional phishing filters rely on rule-based methods of identifying phishing by identifying known phishing sites and senders [[17](https://arxiv.org/html/2401.09727v1/#bib.bib17)]. However, the test environment used to investigate the feasibility of using automatic defense methods against LLM-generated attacks must be flexible enough to incorporate both LLM-generated attacks and defenses involving lateral phishing red-teaming using LLMs, which presents a novel and highly effective approach in cybersecurity exercises, aimed at enhancing organizational defenses against sophisticated phishing threats.

Our investigation, situated within a large public university, delves into the specific cyber threats faced by the institution, with a particular focus on the use of large language models (LLMs) in generating lateral phishing content. In our study, we conducted a large scale study across roughly 9000 employees over the period of 11 months where we created a variety of different phishing email templates. The existing phishing simulation infrastructure of the university’s cyber operations team supports the logging of information of how users interact with simulated phishing emails, collecting information such as if they open the email, click the phishing link or input login credentials. Using this infrastructure, we investigate both human written and LLM generated phishing emails, examining how internal and external organizational information can be used to craft effective lateral spear phishing attacks by capturing the data on how users interact with these simulated phishing attacks.

This comprehensive study not only examines the efficacy of LLM-crafted phishing emails, which we found to be strikingly similar to traditional human-generated lateral spear phishing attacks, but also incorporates valuable insights from the university’s cyber operations team. In one of our critical experiments, it was observed that about 10% of email recipients at the university were compelled to input their login credentials when targeted by LLM-generated phishing emails. This underscores the persuasive effectiveness of these AI-crafted attacks. Our research further explores the factors that heighten vulnerability to these sophisticated attacks and pinpoints the elements within the phishing emails that impact recipients’ decision-making, especially in terms of whether to engage with or dismiss these emails. Notably, the use of information specific to the internal versus external dynamics of the organization proved to be a significant factor in the success rate of these LLM-driven lateral spear phishing attempts. Additionally, we present insights from the organization’s cyber operations team, who emphasize the need for updated phishing trainings and warnings to better address the nuances of LLM phishing threats. Their expert perspectives shed light on potential mitigation strategies and the necessity of evolving educational approaches to keep pace with these emerging cyber threats. To combat these sophisticated attacks, our study further showed advanced machine learning-based detection techniques designed specifically to identify LLM-generated phishing emails. These methods have achieved a high success rate, with an F1-score of 98.96, successfully identifying phishing attempts that had bypassed existing security protocols. The integration of these novel detection techniques into the university’s existing anti-phishing infrastructure is highlighted as a potential next step towards enhancing the organization’s resilience against these increasingly complex and evolving cyber threats.

Ultimately, this research provides the following key contributions.

- •
    
    We undertake a thorough study to show the state of cyber security threats at a large public university. Alongside this we show how insights from the organization’s cyber operations team drive our investigation into LLM generated spear phishing attacks.
    
- •
    
    We conduct extensive experiments spanning 11 months across roughly 9000 employees at a large public university to analyze how they interact with phishing emails. We further show how LLM generated lateral spear phishing emails utilizing internal information can is a significant security risk.
    
- •
    
    We develop and a large-scale detection framework for identifying emails generated by large language models, demonstrating rapid detection capabilities with minimal operational overhead.
    

## 2 Organization Security Incident Investigation: A Motivational Study

![https://arxiv.org/html/2401.09727v1/x1.png](https://arxiv.org/html/2401.09727v1/x1.png)

Figure 1: Schematic of Red-teaming infrastructure for lateral phishing simulations. This diagram illustrates the setup used for simulating phishing attacks within the organization to test the response efficacy of employees and IT systems.

To contextualize our focus on studying LLMs for lateral spear phishing, we initially delve into the background of the organization central to this research. Following this, we outline the cyber security threats it encounters, highlighting phishing as a predominant and financially damaging cyber threat. Subsequently, we detail a specific instance of lateral spear phishing that the organization experienced earlier in the year. Building on this, we draw upon insights from the organization’s cyber operations team, which inform the design of our phishing experiments and shape the research questions we aim to answer through this study.

### 2.1 Organization Background

The organization has a workforce of approximately 9,000 employees and contributes approximately $2.5 billion to the local economy. Its customer segment, predominantly students, numbers just under 35,000. Spanning over 700 acres, the main campus encompasses four distinct campuses and features over sixty buildings. The IT organization delivers enterprise-level services within a multifaceted and federated environment, comprising both centralized and distributed IT operations, with the majority of services being managed by the central IT team. This department adheres to a well-established ITIL framework and primarily aligns with NIST security standards to meet research and educational regulatory requirements. The network, both wired and wireless, regularly supports over 70,000 connected devices. The cyber operations team operates using the MITRE framework, conducting monthly phishing simulation campaigns, weekly distributions of scam alerts for educational purposes, and collaborating with external groups for penetration testing exercises (blue team versus red team scenarios). The team is bolstered by senior-level students who participate as interns or work-study members, gaining practical experience in the field. All first-level IT support is centralized in a large unit, equipped to manage calls, incidents, and requests from all campus locations. The diagram in Figure [1](https://arxiv.org/html/2401.09727v1/#S2.F1) illustrates the deployment of lateral phishing exercises and how it takes place within the organization.

### 2.2 Lateral Phishing and Impact

To motivate why we focus on lateral phishing email attacks, we first examine the existing state of information security within the organization and then conduct a comprehensive analysis of cyber security incidents from 2022-2023. Security incidents in this context, are part of daily operations that typically include tasks that are of low to moderate impact on systems and operations. These incidents require prompt and diligent attention. Although they do not immediately signal a breach, their significance escalates if not addressed efficiently. The cyber operations team takes a proactive approach to investigating these incidents, which often emerge as alerts for unusual login attempts, detected malware or viruses, correlations in event logs, and minor deviations from policy standards. Timely and effective management of these incidents is crucial in preventing their escalation into more serious situations. As depicted in Figure [3](https://arxiv.org/html/2401.09727v1/#S2.F3), the period witnessed roughly 13,000 security incidents. Notably, 35.2% of these incidents were classified as phishing email campaigns, constituting the majority of all security incidents. Further analysis revealed a concerning trend in phishing incidents. In 2022, there were 1,947 incidents, which escalated to 2,245 in 2023, marking an approximate 15% increase in just one year. Over the last 60 days, our security infrastructure automatically detected 18,693 phishing attempts. Despite this, 934 attacks eluded the automatic filters and led to successful phishing incidents. This data indicates that around 5% of phishing attacks went undetected by our existing security measures and resulted in a phishing incident.

| Category | Count |
| --- | --- |
| Blocked at the Edge | 2,247,769 |
| Total Email Processed | 38,855,303 |
| Forward Email Rules | 5,709,107 |
| Blocked Emails with Malware | 8,189 |
| Blocked Phishing Emails | 752,087 |
| Blocked Spam Emails | 2,136,707 |
| Blocked Malicious URLs | 9,342 |
| Retroactive Phishing Emails Removed | 40,944 |
| Retroactive Emails with Malware Removed | 251 |
| Retroactive Spam Emails Removed | 7,894 |
| Total Email Delivered | 30,180,782 |

TABLE I: Summary of last 90 days inbound Emails

We also closely examine the last 90 days of Inbound Mail, as detailed in Table [I](https://arxiv.org/html/2401.09727v1/#S2.T1), a period that aligns with the duration of our phishing exercise. Throughout this time, the organization processed over 38 million emails, successfully delivering 30 million to user mailboxes. Close to 3 million emails were blocked, and 40,944 phishing emails were subsequently removed, highlighting the ongoing challenge of phishing attempts bypassing initial security protocols. The cyber operations team’s investigation into each phishing campaign involves a detailed analysis, executed by a combination of personnel and automated systems. This typically amounts to more than 30 hours of collaborative work, drawing on resources from all levels of the IT organization. The cost associated with soft labor hours for addressing these phishing incidents is estimated at $4.8 million over the past two years. Beyond the $4.8 million figure, phishing poses additional, financial burdens that warrant recognition. Interruptions stemming from phishing attacks precipitate productivity losses, a substantial factor not encompassed within the direct cost calculation. Furthermore, there are indirect expenses linked to the consequences of these security breaches, including potential data loss, legal ramifications, and harm to the organization’s reputation. These collateral costs, though not explicitly quantified in the $4.8 million, place a strain on the organization’s resources. Equally important is the financial commitment towards bolstering the security infrastructure as a response to the phishing threat. The investment in advanced security tools, sophisticated detection platforms, and continuous cyber awareness training forms a critical part of expenditures due to the threat of phishing.

![https://arxiv.org/html/2401.09727v1/x2.png](https://arxiv.org/html/2401.09727v1/x2.png)

Figure 2: Diverse participation in red-teaming exercises across various departments and job functions within the organization.

To enhance the relevance of our study on lateral phishing emails, we also underscore a recent spear phishing incident within our organization. In this lateral spear phishing incident, seven accounts were impacted, resulting in a combined effort of more than 2,000 soft labor hours and an estimated cost of $73,500 to the organization. In the first half of 2023, a lateral spear phishing operation set a precedent for our phishing exercises in October and November. This attack specifically targeted high-ranking individuals, employing a sense of urgency in the email content and using cunning methods to propagate the attack, including creating inbox rules so the attacks would hide in plain sight. The primary aim was to harvest credentials, with a focus on diverting financial transactions to an overseas account. This sophisticated method underscored the urgent need to improve our defenses against such attacks. It also provided a valuable opportunity to assess the effectiveness of our current training protocols. In response, our organization revised its monthly training modules and invested in an advanced phishing detection system that utilizes behavioral analytics to more efficiently detect various phishing schemes.

![https://arxiv.org/html/2401.09727v1/x3.png](https://arxiv.org/html/2401.09727v1/x3.png)

Figure 3: Breakdown of security incidents at the organization in 2023 with phishing campaigns constituting 35.2% of total incidents.

### 2.3 Social Engineering Observations

Social engineering tactics play a pivotal role in the effectiveness of phishing campaigns, as observed by our organization’s cyber operations team. These insights reveal how attackers manipulate human psychology, often through seemingly legitimate offers or urgent requests, to trick individuals into compromising their security. One significant trend observed in lateral phishing attacks within the organization involves targeting recent contacts, especially direct reports, when the compromised account belongs to a supervising employee, validating observations on previous research on lateral phishing attacks [[18](https://arxiv.org/html/2401.09727v1/#bib.bib18), [14](https://arxiv.org/html/2401.09727v1/#bib.bib14)]. This method adds an insidious layer to the attack, leveraging the existing trust within professional hierarchies. Another notable example observed by the cyber operations team is phishing emails disguised as job opportunities, primarily targeting students. These emails cunningly use external links or attached Word documents as bait. In a broader context, phishing emails regarding Duo MFA, credential renewals, or resets are crafted with urgency to deceive recipients across the organization. Another widespread tactic involves falsely alarming users about the de-provisioning of their email accounts if they fail to take immediate action. Faculty and staff are often the targets of these sophisticated phishing attempts. These include spoofed login pages from recognized domains (such as r20.rs6.net) and emails with forged usernames from external domains, employing spearphishing strategies. To enhance their deceptive appearance, many phishing emails include images linked to the organization or Microsoft, exploiting the trust associated with these entities. This integration of social engineering techniques into phishing campaigns underscores the need for continual vigilance and education in cyber security practices.

The cyber operations team also discussed the potential threat of LLMs toward generating highly sophisticated spear phishing emails. Traditional phishing filters, which predominantly rely on rule-based systems or databases of known phishing sites and senders [[17](https://arxiv.org/html/2401.09727v1/#bib.bib17), [19](https://arxiv.org/html/2401.09727v1/#bib.bib19)], are finding it increasingly difficult to detect these AI-generated emails. The reason is that these emails often bypass standard detection rules by avoiding typical phishing indicators such as whether the email is sent by an unusual sender, and they are not yet listed in existing databases of known threats. As a result, these emails, which can be highly personalized and contextually relevant, pose a significant threat as they are difficult to distinguish from genuine communications. To effectively counter this new wave of AI-generated spear phishing, they expressed a need for more advanced solutions. These include AI-driven filters that can understand context and intent, behavior-based analysis, and continuous learning systems that adapt to evolving threats. Additionally, human vigilance remains a critical component. Educating users about the sophistication of these attacks and fostering a culture of skepticism and caution is essential in mitigating the risk posed by these advanced phishing attempts.

### 2.4 Security Incident Conclusion

The phishing email templates created for our research are significantly influenced by the expert insights of our organization’s cyber operations team, particularly regarding the dynamics of supervisor-direct report relationships in phishing attacks. These insights have led to the development of templates that mimic this specific relationship, using elements of urgency and personalization to create a sense of legitimacy and prompt action. This approach is grounded in the team’s observations of past successful phishing campaigns, where the exploitation of the hierarchical trust in an organization proved to be a particularly effective strategy.

Moreover, the team’s analysis highlighted the potential vulnerability of our organization to phishing attacks that use publicly available information. This understanding inspired the creation of a novel template that does not rely on the supervisor-direct report dynamic. Instead, it utilizes information that is publicly accessible external information about the organization. It serves as a crucial indicator of how well our organization can withstand phishing attempts that are based on public knowledge, rather than personal relationships, which may become more effective and prevalent as LLMs are able to generate more convincing and contextually relevant content. As these models become increasingly sophisticated in synthesizing and utilizing publicly available information, they can create phishing messages that are highly tailored and believable, potentially bypassing traditional security awareness trained on recognizing more personalized, direct-report based lateral phishing attempts.

The key observations from the security incident team that we use to drive our investigation can be summarized as the following:

- •
    
    Spearphishing emails often mimic communications from a supervisor to their direct reports, presenting a deceptive appearance of legitimacy.
    
- •
    
    Many phishing attacks disguise themselves as urgent internal communications, impersonating various departments such as HR, Finance, Legal, IT, or Event Planning.
    
- •
    
    Instances have been noted where mass messaging is executed through compromised internal email accounts.
    
- •
    
    The crafting of spear phishing emails may involve the use of LLMs.
    

### 2.5 Research Questions

RQ1: How effective are lateral phishing attacks across a large educational organization? Understanding the effectiveness of lateral phishing attacks is critical to assessing organizational security vulnerabilities. This research question is novel as it investigates a large educational institution, contrasting with previous large-scale phishing research which predominantly focuses on commercial organizations. Our approach offers a unique perspective compared to the findings presented in previous prominent large scale phishing studies [[14](https://arxiv.org/html/2401.09727v1/#bib.bib14), [15](https://arxiv.org/html/2401.09727v1/#bib.bib15)]. The first part of this study involves multiple phishing email campaigns across 11 months where we report statistics on how users engage with the simulated phishing emails.

RQ2: Do LLM crafted lateral phishing emails have similar impact as human-generated lateral phishing emails? This question is essential to evaluate the evolving threats in cybersecurity, particularly the effectiveness of AI in mimicking human phishing tactics. In the final month of this phishing study, a similar phishing exercise is conducted using LLM-generated emails, allowing for a comparison of the impact between AI-generated and human-generated phishing attempts.

RQ3: How does the effectiveness of LLM-generated spear phishing emails differ when using internal versus external organizational information? This question is crucial as it explores the potential threat level posed by phishing attacks crafted with varying degrees of insider knowledge. Specifically, we investigate the efficacy of spear phishing attacks that utilize information about an organization’s structure and internal details compared to those based solely on publicly available information. The study involves an analysis where an LLM is used to create phishing emails. One set of emails is generated using data accessible from the organization’s public website, while another set leverages more detailed internal information.

RQ4: How effective are phishing training and warnings in lateral phishing across an organization? Evaluating the effectiveness of existing phishing countermeasures is crucial for improving organizational security protocols [[20](https://arxiv.org/html/2401.09727v1/#bib.bib20)]. The study involves a targeted analysis of individuals who received phishing training, especially those who previously entered credentials in a phishing attack, to measure the training’s impact on reducing susceptibility to phishing.

RQ5: Can LLM detectors be used to identify LLM-generated phishing emails? Investigating the effectiveness of LLM detectors in identifying AI-generated emails is vital for analyzing how LLM generated phishing emails may be combated. The research includes an analysis where human generated emails are regenerated using an LLM and tested against a handful of machine text detectors. Both existing machine text detectors and a system using LLM embeddings are tested for their effectiveness in distinguishing machine-generated emails.

## 3 Threat Model

The proliferation of LLMs marks a significant shift in the domain of lateral spear phishing, with these models introducing complexities of an unprecedented scale. This paper dissects the evolving threat landscape, pinpointing three pivotal roles: (1) Adversarial agents who harness compromised email accounts alongside LLMs to forge highly individualized and persuasive phishing communication. These communications are carefully tailored to target specific individuals within an organization [[21](https://arxiv.org/html/2401.09727v1/#bib.bib21)], with the ultimate goal of illicitly obtaining sensitive information and breaching secure systems [[22](https://arxiv.org/html/2401.09727v1/#bib.bib22)]. The spectrum of adversaries ranges from solitary hackers to state-sponsored groups [[23](https://arxiv.org/html/2401.09727v1/#bib.bib23)], exploiting two key vulnerabilities. Firstly, there is the inherent trust employees place in communication that appears familiar. This trust allows adversaries to craft and insert phishing messages into an organization’s communication flow undetected, exploiting this implicit trust to their advantage [[24](https://arxiv.org/html/2401.09727v1/#bib.bib24), [25](https://arxiv.org/html/2401.09727v1/#bib.bib25)]. Secondly, the sophistication of LLMs presents a substantial challenge to traditional security systems, which are often not equipped to detect the nuanced and human-like text produced by such models, allowing this kind of content to slip past established detection mechanisms [[26](https://arxiv.org/html/2401.09727v1/#bib.bib26)]. (2) Targets who receive these carefully engineered phishing communications. These targets span across all levels of hierarchy and profiles, and they may not always possess the necessary cybersecurity awareness to identify and avoid these sophisticated phishing attempts. (3) IT Professionals who are tasked with the development and administration of intricate email filters and security operation centers (SOCs) to combat and neutralize these evolving threats. They play a crucial role in implementing and managing advanced security solutions that can effectively detect and mitigate phishing. This study assumes that perpetrators have unauthorized access to both email accounts and Large Language Models (LLMs). These tools enable them to create highly personalized and convincing phishing messages that build trust and create urgency, often resulting in the unintended release of sensitive information or actions that undermine the security of the targeted organization. It is critical to reassess the basic principles of current cybersecurity measures. Typically, these measures focus on identifying well-known patterns of malicious activity, which may not suffice against the more sophisticated and subtly crafted attacks made possible by LLMs. These models can generate text that closely resembles genuine human writing. Furthermore, there is a common overestimation of the level of cybersecurity knowledge within an organization’s staff, ignoring the reality that awareness and training in cybersecurity vary widely among employees.

## 4 Lateral Phishing Simulation Infrastructure

### 4.1 Stakeholder Roles

### 4.1.1 Research Role

For this study, we leveraged the already existing phishing awareness campaign infrastructure to test our research questions. We partnered with the organization’s cyber operations team and acted as advisors to administer the experiment. We helped the university’s cyber operations team prompt the LLM to develop effective phishing email templates. Researchers also acted as scientific advisors to guide the design of the experiments and research questions. Researchers only had access to anonymized data from the cyber operations team to perform analysis.

### 4.1.2 IT Cyber Operations Role

The cyber operations organization is strategically organized into three tiers: Identify and Protect, Threat Intelligence, and Respond and Recover. The team is committed to raising the organization’s security posture and maintain a state of readiness within the institution. To ensure confidentiality, integrity and availability of institutional data and systems in the ever-evolving cyber-threat landscape, the organization emphasizes policy enforcement and compliance to safeguard intellectual property, proactively monitors and assesses cyber-threats keeping the institution alert, and mitigates risk of security incidents to ensure normal operations.

Central to this cybersecurity framework is an overarching emphasis on training and awareness, especially against social engineering types of attacks. Monthly phishing simulation exercises cultivate an informed employee workforce and keep our cybersecurity insurance premiums low. Weekly communication regarding scams and red flags raises the institutions defense mechanisms against sophisticated cyber-threats. It is a constant balancing act of threat detection and response activities, systems patching and risk mitigation strategies complemented by phishing simulations and training.

### 4.1.3 Study Participants

Roughly 9000 employees were subject to the phishing exercises over the period of this 11 month phishing exercise, with 8995 employees receiving phishing emails in the last round of lateral phishing emails. During the last round of phishing emails, a total of 1345 employees held a supervisory role, which is important to note since several of the email templates used in this study relied on lateral phishing attacks where the email was addressed from a supervisor to a direct report, utilizing the trust and familiarity of a common type of organizational relationship.

### 4.2 Phishing Process

The organization leverages a comprehensive phishing training platform designed for realistic cybersecurity training exercises. Phishing campaigns are normally conducted over one to three days and emails are sent during working hours. Employees are sampled in random order and templates are designed to match specific criteria to test the employee’s ability to identify sophisticated phishing attacks. The help desk is particularly impacted during these exercises as they receive calls and reports of suspicious emails. The help desk is not notified of the time frame phishing exercises are conducted to reflect real-world scenarios. This also presents the opportunity to refine their processes and procedures to handle unexpected surge of tickets. The organization also leverages phishing detection tools in several other platforms that cover signature based and behavioral based detection and alerts as well as the ability to orchestrate a full investigation of backtracking the origin in emails of interest. The organization also conducts annual mandatory security training covering a broad range of security topics to ensure employees stay abreast of latest security threats and tactics. To further assist the cyber operations team in reducing the time to respond and resolve phishing incidents, the organization leverages a threat intelligence solution that provides extensive visibility into various entry points to reveal high-impact events and attack insights to further strengthen the team’s response mechanisms.

![https://arxiv.org/html/2401.09727v1/x4.png](https://arxiv.org/html/2401.09727v1/x4.png)

Figure 4: The informational warning message for our simulated phishing tests, detailing immediate steps to follow after clicking on a phishing link.

### 4.2.1 Phishing Emails

This study includes the monthly phishing emails sent through the organization’s phishing training platform from January through November for a total of 11 months worth of phishing data with more than 20 total phishing templates used during this time. The phishing emails sent in the January through September were crafted without any feedback from researchers. The structure and topics of these emails varied, with some emails crafted to take advantage of recent news at the time such as student loan forgiveness. Some emails also included spoofed internal domains, and others included spoofed external domains such as Microsoft, Google, and Zoom. On the other hand, the phishing emails in October and November were crafted with the input of researchers. Like the January through September emails, October emails were also still human written, while the November emails were written using an LLM. The phishing templates used in October and November were crafted based on some of the observations of real-world social engineering tactics from the organization’s cyber operations team alongside researcher suggestions. As such, the phishing emails used in October and November were focused around a few specific themes. These phishing emails included emails from a supervisor to their direct report which leverage internal organizational information, and communications from other internal addresses that leverage external information.

The five phishing emails that were the primary focus of this study were the phishing emails in the October and November phishing exercises, with two different phishing templates occurring in October and three different phishing templates occurring in November. The two templates in October were human written. The first of these human written templates was designed to appear to be authored by the recipient’s supervisor and addressed the recipient by their first name, where the supervisor asks the recipient to click a link to upload some pictures for a presentation next week. The second human written template was designed to appear to be an urgent request from the organizaton’s Human Resources department addressing the recipient by their first name, asking the recipient to click a link to upload their address and phone number.

The next set of templates were the LLM authored phishing emails. There were three different LLM written email templates. The first two templates were written on the topic of an end-of-year holiday event, which appeared to be sent from the supervisor of the recipient, where the recipient was asked to write their suggestions to a spreadsheet that was linked in the email. The first LLM written template addressed the recipient by their first name, but the second LLM written template addressed the recipient by ”Hi Team”. GPT4 from ChatGPT was used to author these emails, being prompted to write an email template about gathering ideas from an end-of-year holiday event where the sender is the supervisor of the email recipient and is written in a mildly informal and friendly tone. The third LLM authored email template was a uniform template that was the same no matter the recipient and utilized external information about the organization. This template was written on the topic of new and exciting food options to be available at the university. The email was to appear to be written by an organizational account, but not someone who the recipients would know. GPT4 from ChatGPT was also used to author this email, and was asked to look at the university’s dining page to understand the style of the university dining writing and to write about new and exciting food options. In this email, the recipients were given a link to view the new menu and dining options.

### 4.2.2 Phishing Training and Warning

The annual security awareness training that employees are automatically enrolled and must complete reinforces the institution’s policy which has awareness of threats embedded with the acceptable use of computing resources. The department also sends weekly ”Scam of the Week” emails with advisories on current trends and brand these use cases with ”Stop, Look, and Think. Don’t be fooled.” at the end of each advisory security safety tips are outlined to watch for emails that contain a sense of urgency, any prompts for a call back, or suspicious context and grammar structure. Employees who are identified to enhance their cybersecurity awareness based on the monthly phishing exercise results are given a training opportunity and two weeks to complete it. Timely training has been shown to raise awareness to these phishing threats [[27](https://arxiv.org/html/2401.09727v1/#bib.bib27)]. They get a periodic reminder and if the training is incomplete then an email goes to their manager. Upon completion of their assigned training they receive a thank you email for completing it and for doing their part to keep the organization safe from cyber attacks. When designing these phishing exercises the following criteria are evaluated: Prior actual security incident types, current trends, Red Flag indicators such us external, internal, sense of urgency, subject, attachments with macros, spoofed domains or email addresses, fake login portals and landing domains.

### 4.2.3 Measurement

In conducting phishing exercises, we closely monitor employee responses, gathering essential metrics such as Sent, Opened, Clicked, Replied, Attachment, Data Entered (without saving credentials), and Reported. By aggregating these metrics with data from previous exercises, we formulate a risk score to evaluate the organization’s security posture and assess the susceptibility of our employee base to phishing attacks. Employees who enter data in these exercises are promptly enrolled in security awareness training, with a completion deadline of two weeks. Additionally, this risk score is benchmarked against industry data to provide insights, track historical trends, and gauge the maturity level of our cybersecurity posture.

In measuring the effectiveness of these attacks, our focus centers on two pivotal metrics: click-through rates and data exfiltration success. Click-through rates are determined by the percentage of recipients who click on links or attachments in the phishing emails, serving as an indicator of the email’s ability to persuade the recipient to take action [[28](https://arxiv.org/html/2401.09727v1/#bib.bib28)]. The data exfiltration success, which in our context refers to the rate at which recipients enter data, provides insight into the effectiveness of LLM-generated emails in compelling recipients to divulge sensitive information. Data exfiltration, particularly in the context of recipients entering data, represents one of the most critical aspects of a phishing attack, as it often involves the surrender of sensitive information, such as login credentials. This breach is particularly serious because once attackers gain access to login details, they can infiltrate the organization’s network, access confidential information, and potentially cause additional harm to other users. Therefore, the rate at which recipients are tricked into entering such sensitive data is a key indicator of the severity and potential impact of a phishing attack [[29](https://arxiv.org/html/2401.09727v1/#bib.bib29), [30](https://arxiv.org/html/2401.09727v1/#bib.bib30), [31](https://arxiv.org/html/2401.09727v1/#bib.bib31)].

| Month | Email Recipients | Emails Opened Link | Clicked Data | Entered | Category of Phishing Emails |
| --- | --- | --- | --- | --- | --- |
| Nov. 2023 | 8,995 | 4,461 (49.59%) | 1,501 (16.69%) | 613 (6.81%) | Event Coordination Scam: Holiday Party Planning, New Dining Options |
| Oct. 2023 | 8,856 | 5,303 (59.88%) | 2,352 (26.56%) | 646 (7.29%) | Conference Pictures Request, Internal HR: Urgent Request |
| Sept. 2023 | 8,495 | 3,078 (36.23%) | 398 (4.69%) | 140 (1.65%) | Spoofed Suspicious Activity, Spoofed Domain Employee Verification |
| Aug. 2023 | 7,860 | 2,511 (31.95%) | 181 (2.30%) | 52 (0.66%) | Password Reset Fraud, Update Payment Information Scam |
| July 2023 | 6,750 | 3,084 (45.69%) | 269 (3.99%) | 100 (1.48%) | Internal Account Spoofed IT Support Login Info Required |
| June 2023 | 6,498 | 2,746 (42.26%) | 262 (4.03%) | N/A* | Microsoft Spoofed Domain without URL Link, Google Spoofed Domain without URL Link |
| May 2023 | 6,809 | 3,034 (44.56%) | 843 (12.38%) | 139 (2.04%) | Callback Voicemail Internal Account, Internal Account Retirement Plan Changes |
| Apr. 2023 | 6,759 | 3,620 (53.56%) | 722 (10.68%) | 53 (0.78%) | Internal HR: Have a message from HR, Message from Accounting |
| Mar. 2023 | 6,729 | 3,107 (46.17%) | 769 (11.43%) | 250 (3.72%) | Spoofed Domain: Need to Verify Information for W2, Personal Tax Information |
| Feb. 2023 | 6,614 | 2,776 (41.97%) | 413 (6.24%) | N/A* | Microsoft Spoofed Support for Password, Dropbox Spoofed Support for Password |
| Jan. 2023 | 6,271 | 2,334 (37.22%) | 210 (3.35%) | N/A* | Docusign Spoofed Document Need Signature, Student Loan Debt Relief Spoofed |

TABLE II: Summary by month of results of phishing exercises conducted. Percentages shown are relative to the number of recipients. Also shown are short descriptions of some of the phishing emails sent during that month’s phishing exercise. Many emails were based on relevant news or events such as student loan forgiveness. Entries with N/A mean that this metric was not collected for that month’s phishing exercise.

### 4.3 Ethics, Safety and Privacy

The primary goal of the phishing simulation exercises is to enhance the employees’ ability to identify and mitigate potential Cyber threats effectively, conduct those in a supportive environment that aids in better preparedness against cyber attacks, and to emphasize learning and skill development in the workforce. In designing a phishing simulation test, the Office of Information Security evaluates collective threat intelligence information and discusses the goals of the exercise with the cyber operations team. Several factors are considered: raising awareness, improve the overall security posture of the organization, the impact to the individual, the timing and frequency of the simulation emails, phishing template design, compliance to existing policies, privacy laws and regulations (CCPA, FERPA, PII, TGC.s2054.519(b), TCC, TSPA) and the level of disruption in normal operations to the organization. This is particularly challenging when conducting Man-in-the-Middle (MitM) phishing simulation exercises, as the population is large and diverse. The team considers the ethical implications in spoofing domains or individual’s accounts and contrasts those with real-world phishing campaigns. Separation of duties is a critical centerpiece of the process to ensure integrity of the data and the process itself, and to minimize the risk of mishandling sensitive information. During an exercise, any data that a participant enters to a login form (credentials harvesting) or interception simulation is not stored. Only the aggregated results of the data collected and Risk Score calculated during a monthly test are presented to executive leadership to ensure individuals’ privacy is protected. Phishing simulation exercises can raise employee concerns, so it is important to have an empathetic and informative approach, and present those as valuable learning opportunities.

In this study, our team collaborated with the University’s cyber operations team, which had previously been conducting exercises using phishing emails to enhance awareness and educate users about the risks associated with such emails. The cyber operations team was responsible for managing all personally identifiable information (PII), ensuring its anonymization before providing the researchers with statistical data. Upon reviewing our research protocols, the IRB of our institution determined that our project did not fall under the regulatory criteria of the DHHS or the FFDA. Consequently, it did not require further oversight from the IRB.

## 5 Experiments and Discussion

### 5.1 RQ1: Effectiveness of Human-Crafted Lateral Phishing

To answer RQ1, we first show the results of 11 months of phishing exercises across a large educational organization. The results of these phishing exercises are presented in Table [II](https://arxiv.org/html/2401.09727v1/#S4.T2), showing the number of phishing email recipients, phishing emails opened, phishing links clicked and data entered. Furthermore, a short description of the phishing emails in the month’s phishing exercise were included to provide some insight into what topics and themes were effective attacks. An analysis of the data reveals significant fluctuations in the success rates of these simulated phishing attacks. The effectiveness of lateral phishing can be primarily gauged by two key metrics: the percentage of recipients who opened the phishing link, and more critically, the percentage of those who further engaged by clicking on the link and entering their information.

The highest open rate was observed in October (59.88%), while the lowest was in August (31.95%). These variations can potentially be attributed to the nature of the email content, which may exploit the specific contexts and expectations within an educational setting. Emails with a sense of urgency or relevance to common educational or administrative themes, such as ”Internal HR: Urgent Request” or ”Conference pictures requested,” appeared to be more effective in prompting recipients to open the links.

The rate at which recipients clicked on the links and entered their information is a more direct measure of the phishing attack’s success. In this context, October again stands out with a click-through rate of 26.56% and an information entry rate of 7.29%. This suggests a significant vulnerability among the targeted individuals to such types of attacks.

### 5.2 RQ2: Impact of LLM-Crafted Lateral Phishing

| Email | Email Template | Email Recipients | Emails Opened | Link Clicked | Data Entered |
| --- | --- | --- | --- | --- | --- |
| Human Written | Supervisor to Direct Report | 4,539 | 2,875 (63.34%) | 1,701 (37.48%) | 351 (7.73%) |
| LLM Generated | Supervisor to Direct Report | 6,070 | 3,479 (57.31%) | 1,385 (22.81%) | 607 (10.00%) |
| Human Written | Critical Internal Communications | 4,317 | 2,428 (56.24%) | 651 (15.01%) | 295 (6.83%) |
| LLM Generated | Critical Internal Communications | 2,925 | 982 (33.57%) | 116 (3.97%) | 6 (0.21%) |
|  | Total Human Written | 8,856 | 5,303 (59.88%) | 2,352 (26.56%) | 646 (7.29%) |
|  | Total LLM Generated | 8,995 | 4,461 (49.59%) | 1,501 (16.69%) | 613 (6.81%) |

TABLE III: Human-crafted and LLM Crafted lateral phishing emails. Percentages are relative to the number of email recipients.

To next answer RQ2, Table [III](https://arxiv.org/html/2401.09727v1/#S5.T3) is shown for a comparative analysis of human-written versus LLM-generated lateral phishing emails. For the ”Supervisor to Direct Report” template, human-written emails exhibit a higher open rate (63.34%) compared to LLM-generated emails (57.31%). This suggests that human-written emails may initially engage recipients more effectively. However, in terms of eliciting specific responses such as clicking on links and entering data, LLM-generated emails demonstrate a noteworthy performance. The data entry rate for LLM-generated emails in this category is notably higher (10.00%) compared to human-written ones (7.73%), indicating their potential to effectively persuade recipients to take action.

In the case of ”Critical Internal Communications,” there is a marked difference in effectiveness between human-written and LLM-generated emails. The human-written emails outperform LLM-generated emails in all metrics. The lower impact of LLM-generated emails in this category can be attributed to the content’s relevance and urgency. The LLM-generated emails, focusing on less critical topics like dining options changes, failed to engage recipients as effectively as the human-written emails that dealt with more pressing matters like HR requests. This variation underscores the importance of content relevance in determining the effectiveness of phishing emails, whether human-crafted or AI-generated. The stark contrast in the effectiveness of these templates underscores the importance of context and personalization in phishing attacks. The success of the phishing emails from Table [III](https://arxiv.org/html/2401.09727v1/#S5.T3) aligns with insights from our discussions with the cyber operations team, which noted that timely attacks based on an organization’s calendar of events are effective in university-targeted phishing. This tendency further emphasizes the need for heightened vigilance and advanced detection methods in cybersecurity strategies, especially in anticipating and countering LLM-generated phishing emails that exploit specific organizational events and relationships.

The subtle differences in language and tone between the human-written and LLM-generated emails may contribute to these divergent outcomes. Despite these differences, the overall comparison across all categories indicates a close alignment in the effectiveness of human-written and LLM-generated emails. The total data entered rates are relatively similar (7.29% for human-written vs. 6.81% for LLM-generated), suggesting that under certain conditions, LLM-generated emails can achieve an impact comparable to that of human-written emails.

### 5.3 RQ3: LLM Phishing using Internal vs External Organization Information

| Email Template | Email Recipients | Emails Opened | Link Clicked | Data Entered |
| --- | --- | --- | --- | --- |
| Targeted Internal Information | 3,022 | 1,735 (57.41%) | 606 (20.05%) | 295 (9.76%) |
| Group Internal Information | 3,048 | 1,744 (57.22%) | 779 (25.56%) | 312 (10.24%) |
| External Information | 2,925 | 982 (33.57%) | 116 (3.97%) | 6 (0.21%) |

TABLE IV: Internal vs External information for LLM Phishing. Percentage shown is percent relative to the number of email recipients.

To answer RQ3, we present Table [IV](https://arxiv.org/html/2401.09727v1/#S5.T4). The analysis of LLM-generated spear phishing emails, distinguished by their use of internal versus external organizational information, provides critical insights into their varying effectiveness. The key distinction lies in how these emails engage with the recipients—emails categorized under ”Targeted Internal Information” utilize the recipient’s name, thereby creating a sense of direct and personal communication. This approach resulted in a 57.41% open rate, a 20.05% link click rate, and a 9.76% data entry rate, indicating a high level of effectiveness. The personalization aspect likely plays a significant role in this success, as recipients might perceive such emails as more credible and relevant.

In contrast, the ”Group Internal Information” emails, which address recipients with a general ”Hi Team,” also show strong engagement 57.22% open rate, 25.56% link click rate, and 10.24% data entry rate). Despite the lack of individual targeting, these emails still resonate effectively, possibly due to the perceived relevance to the group at large, which may prompt a sense of collective urgency or responsibility. However, when it comes to emails leveraging ”External Information,” such as discussing dining options at the university, the effectiveness markedly decreases. These emails exhibit only a 33.57% open rate, a 3.97% link click rate, and a notably low 0.21% data entry rate. This significant drop in engagement underscores the importance of contextual relevance and familiarity in spear phishing attacks. Emails with external content, lacking direct ties to internal operations or personalized touchpoints, are less likely to be perceived as legitimate or urgent, leading to lower interaction rates.

This comparison clearly demonstrates that LLM-generated spear phishing emails are more effective when they incorporate internal organizational information, whether targeted or group-oriented, as opposed to external content. The effectiveness of spear phishing is evidently heightened by the use of personalized or internally relevant information, emphasizing the need for heightened awareness and education about such sophisticated phishing tactics within organizations.

### 5.4 RQ4: Effectiveness of Phishing Training and Warnings

To answer RQ4, we perform a sub-analysis that focuses on a specific subset of individuals: those who previously entered data in the human-crafted phishing email experiment during the October phishing exercises and subsequently received phishing training. This analysis is crucial in understanding the effectiveness of training in mitigating susceptibility to phishing, particularly in the context of sophisticated LLM-crafted lateral phishing emails.

The results from this sub-analysis, as shown in Table [V](https://arxiv.org/html/2401.09727v1/#S5.T5), reveal some concerning trends. Among those who received phishing training, a high percentage still fell prey to the LLM-crafted phishing emails, especially in the supervisor-to-direct-report scenarios. In the first scenario, where the supervisor’s email mentioned the recipient’s name, 77.88% of the 208 targeted individuals opened the email, 36.05% clicked on the link, and a significant 24.51% entered data. Similarly, in the second scenario, with the team mentioned, 81.53% of 222 targeted individuals opened the email, 40.09% clicked on the link, and 20.72% entered data. These rates are noticeably higher than the general population’s response in the previous experiments, indicating that even after training, these individuals were 2-3 times more vulnerable to entering data from LLM-crafted lateral phishing attacks than the rest of the population. This points to the need for more effective training measures to reduce phishing vulnerability.

| Email Template | Email Recipients | Emails Opened | Link Clicked | Data Entered |
| --- | --- | --- | --- | --- |
| Targeted Internal Information | 208 | 162 (77.88%) | 75 (36.05%) | 51 (24.51%) |
| Group Internal Information | 222 | 181 (81.53%) | 89 (40.09%) | 46 (20.72%) |
| External Information | 216 | 85 (39.35%) | 0 (0.00%) | 0 (0.00%) |
| Total | 646 | 428 (66.25%) | 164 (25.38%) | 97 (15.01%) |

TABLE V: LLM crafted lateral phishing emails on the subset of users who entered data in the human phishing email experiment and then received phishing training. Percentage shown is percent relative to the number of email recipients.

### 5.5 RQ5: Identifying and Building Defense against LLM-Generated Phishing Emails

To answer RQ5, we evaluate some machine-generated text detection models on emails written by an LLM. To test the capability of existing machine-generated text detection systems to detect LLM generated emails, we first utilize a dataset of 5,000 human written email samples from the dataset by Chakraborty (2023) [[32](https://arxiv.org/html/2401.09727v1/#bib.bib32)]. Each email is then rewritten with the Vicuna 13B v1.5 model from HuggingFace [[33](https://arxiv.org/html/2401.09727v1/#bib.bib33)]. The Vicuna model was introduced by Zheng et al. [[34](https://arxiv.org/html/2401.09727v1/#bib.bib34)] and a key feature of Vicuna is that it utilizes instruction tuning, which refines the model’s ability to understand and adhere to specific directives [[35](https://arxiv.org/html/2401.09727v1/#bib.bib35)]. For the Vicuna model implementation we use 4-bit quantization and a context window of 16,384 tokens. In our experiment, Vicuna is consistently prompted to revise each email sample, resulting in pairs of human and machine written texts. The prompt used for rewriting the human written emails is as follows: ”Revise the following email for me. Only reply with the revised email and do not print anything else. Also, Do not include a subject in your answer. Here is the email text: [EMAIL TEXT]”.

We test four models from the work of Pu et al. [[36](https://arxiv.org/html/2401.09727v1/#bib.bib36)]: BERT-Defense, GLTR-BERT, GLTR-GPT2, and RoBERTa-Defense. GLTR-BERT and GLTR-GPT2 distinguish synthetic from genuine text by leveraging token probability distributions. These methods are based on the premise that synthetic text often incorporates tokens with high probability rankings in language models. GLTR derives features from token rankings in the Top-10, Top-100, and Top-1000, which is then processed by a logistic regression classifier. GLTR-BERT employs BERT as its base language model, while GLTR-GPT2 uses GPT2-XL. Their training involved 4,000 articles from WebText [[37](https://arxiv.org/html/2401.09727v1/#bib.bib37)] for the human class and GPT2-XL generations for the synthetic class. BERT-Defense is a binary classifier built upon the BERT-Large pretrained language model through the addition of a binary classification layer. Inspired by BERT-Defense, RoBERTa-Defense uses the RoBERTa language model as a base with a layer for binary classification. BERT-Defense was trained on 10,000 articles each from WebText for real articles and GPT2-Large for synthetic ones, while RoBERTa-Defense used the RealNews dataset and GROVER [[38](https://arxiv.org/html/2401.09727v1/#bib.bib38)] generations, with 5,000 articles from each for genuine and synthetic texts, respectively.

To show that LLM generated emails can be detected, we first evaluate the four detectors using their base trained weights to test their ability to generalize to the phishing email domain without any modifications. Then, we perform a fine-tuning experiment following the work of Pu et al. [[36](https://arxiv.org/html/2401.09727v1/#bib.bib36)] on the models to show that the model’s performance can be significantly improved when exposed to data in the email domain. We fine-tune BERT-Defense and RoBERTa-Defense using samples from the target distribution using 100 samples, 50 from both the human and machine class. The evaluation metrics we present are the precision, recall, and F1 score with respect to the machine class. The first 4 rows of Table [VI](https://arxiv.org/html/2401.09727v1/#S5.T6) show varied performance of the base models, with RoBERTa-Defense achieving the highest F1 score of 67.1, and GLTR-GPT2 performing poorly with an F1 score of 6.6, suggesting challenges of the base models to generalize to LLM generated emails. In rows 5-8 of Table [VI](https://arxiv.org/html/2401.09727v1/#S5.T6), we present the results of our fine-tuning experiment and note that all models exhibit a substantial improvement in performance. BERT-Defense and GLTR-GPT2, which had the worst base model performance showed the largest improvements in this fine-tuning experiment, with both models having an increase in F1 score by more than 69%.

We also build a model, T5-LLM Email Defense, using the T5 (Text-to-Text Transfer Transformer) encoder [[39](https://arxiv.org/html/2401.09727v1/#bib.bib39)] to distinguish between human and LLM generated email texts. The model architecture integrates the T5 encoder model with an additional classification layer to perform binary classification. We choose to use the T5 encoder model over the full T5 model since binary classification requires understanding and categorizing of input text, which is only a function of the encoder. T5-LLM Email Defense is trained on our dataset of human and LLM generated emails, using the AdamW optimizer and a linear learning rate scheduler. The performance results are in the bottom row of Table [VI](https://arxiv.org/html/2401.09727v1/#S5.T6), showing the highest F1 score of 98.96.

| Model | Data Source | P | R | F1 |
| --- | --- | --- | --- | --- |
| BERT-Defense | WebText/GPT2-Large | 33.3 | 15.0 | 20.7 |
| RoBERTa-Defense | RealNews/GROVER | 66.0 | 68.2 | 67.1 |
| GLTR-BERT | WebText/GPT2-XL | 100 | 22.4 | 36.6 |
| GLTR-GPT2 | WebText/GPT2-XL | 94.4 | 3.4 | 6.6 |
| BERT-DefenseEmail | LLM Generated Emails | 87.6 | 92.0 | 89.8 |
| RoBERTa-DefenseEmail |  | 97.1 | 100 | 98.5 |
| GLTR-BERTEmail |  | 86.5 | 90.0 | 88.2 |
| GLTR-GPT2Email |  | 80.0 | 72.0 | 75.8 |
| T5-LLMEmail Defense (ours) | LLM Generated Emails | 99.03 | 98.89 | 98.96 |

TABLE VI: Performance metrics of existing base detectors, fine-tuned versions of the existing base detectors, and our own detector with respect to the machine class.

### 5.6 Overall discussion and findings

Discussions with the cyber operations team have yielded several key takeaways from the findings of the experiments. Firstly, there is a pressing need to raise awareness about the sophistication of phishing emails. Particularly with the help of LLMs, such emails may not always contain typos or obvious red flags; they can be well-crafted and may even appear to come from a trusted supervisor. The training and awareness programs need to emphasize that any account, particularly those in higher roles, can be compromised and pose significant risks to the organization. The impact of campaigns targeting high-ranking roles could be considerable, and thus, any security incidents involving VIPs or high-level accounts should be treated with utmost urgency [[40](https://arxiv.org/html/2401.09727v1/#bib.bib40), [41](https://arxiv.org/html/2401.09727v1/#bib.bib41), [42](https://arxiv.org/html/2401.09727v1/#bib.bib42)]. Given that the experiments showed that the supervisor to direct report phishing attacks were highly successful, the rationale is to quickly address the heightened risk of the attack spreading more effectively throughout the organization since attacks can move laterally within the organization [[43](https://arxiv.org/html/2401.09727v1/#bib.bib43)]. Such attacks can lead to extensive incident remediation efforts and substantial financial implications. Moreover, the ripple effect of these phishing emails, spreading both internally and externally, poses a serious threat to the organization’s reputation. It elevates the risk of a data breach and can potentially harm long-standing relationships. Prioritizing incidents involving supervisory accounts acknowledges the amplified risk these positions carry and is a strategic move to contain and mitigate the wider organizational impact of such phishing attacks.

The after action review conducted by the cyber operations team yielded crucial insights into the efficacy of current email filtering platforms and the level of employee preparedness in identifying phishing emails, particularly those generated by LLMs. Given the sophistication of LLM-generated emails, which often lack grammatical errors and appear highly credible, it’s imperative to enhance the security awareness training program. This updated training should focus on educating employees to discern subtle cues, such as the overall context of the email and the nature of the request. Alongside recognizing these nuances, it is equally important for employees to be alert to common phishing red flags like the urgency of requests and the origin of URLs or attachments.

In parallel with employee training, it is critical to refine the email filtering platforms to detect phishing attempts more effectively. This includes going beyond traditional red flags and incorporating advanced detection techniques such as mail header analysis, monitoring unusual sender behaviors, comprehensive URL and attachment analysis, content scrutiny, recipient analysis, sender reputation assessment, and identifying spoofed display names or domains. A crucial addition to these methods is the implementation of LLM detectors that can identify inconsistencies in writing style and deviations from the sender’s typical communication pattern or discuss unfamiliar topics.

When an LLM-generated email is detected, proactive measures should be taken to mitigate its potential impact. One potentially effective strategy is to automatically tag such emails, informing the recipient of the potential risks. This tag would act as an immediate visual cue, alerting the recipient that the email has been flagged as being potentially LLM-generated, thus warranting extra scrutiny. Email tagging has been investigated in previous research as it augments users ability to more quickly categorize content [[44](https://arxiv.org/html/2401.09727v1/#bib.bib44), [45](https://arxiv.org/html/2401.09727v1/#bib.bib45)]. Currently within the organization, a similar tagging methodology is used to indicate emails that come from outside the organization, assigning an [EXTERNAL] tag to all such emails. Such tags would not only serve as a direct warning but also reinforce the training employees receive, bridging the gap between theoretical knowledge and practical application. This dual approach of enhancing both technological defenses and employee vigilance could be part of a defense strategy against the evolving landscape of LLM-generated phishing threats. Future research could investigate email tagging for LLM-generated content to see if these tags could heighten user awareness to LLM phishing threats.

## 6 Related Prior Work

Phishing, a widely recognized cybersecurity threat, has been extensively researched due to its prevalence in targeting both individuals and organizations [[46](https://arxiv.org/html/2401.09727v1/#bib.bib46), [47](https://arxiv.org/html/2401.09727v1/#bib.bib47)]. Characterized by its broad and indiscriminate approach, phishing attacks often aim to deceive a large audience through misleading emails or messages to illicitly acquire sensitive data [[48](https://arxiv.org/html/2401.09727v1/#bib.bib48)]. The success of these attacks is largely attributed to the use of persuasive and deceptive techniques in crafting the content, which are designed to exploit human vulnerabilities [[49](https://arxiv.org/html/2401.09727v1/#bib.bib49)]. Other studies instead investigate the differences in how some people better manage phishing emails in their inbox [[50](https://arxiv.org/html/2401.09727v1/#bib.bib50)]. Transitioning from this broader perspective, spearphishing represents a more refined form of phishing. Distinguished by its highly targeted nature, spearphishing attacks are not only meticulously crafted but are also deeply personalized, targeting specific individuals or entities within organizations. These attacks often involve elaborate social engineering strategies, leveraging detailed knowledge about the target to increase their efficacy [[51](https://arxiv.org/html/2401.09727v1/#bib.bib51)]. Recent studies indicate that spearphishing is not only more successful than general phishing but also more challenging to detect due to its tailored approach and exploitation of specific individual or organizational traits [[7](https://arxiv.org/html/2401.09727v1/#bib.bib7)]. The evolution of spearphishing tactics, including the use of sophisticated psychological manipulation and the exploitation of social networks, has significantly raised the stakes in the realm of cybersecurity threats [[52](https://arxiv.org/html/2401.09727v1/#bib.bib52)].

In recent years, the landscape of phishing attacks has become increasingly sophisticated and targeted. According to the Check Point Software Technologies Ltd.’s Brand Phishing Report for Q3 2023, Walmart emerged as the most impersonated brand in phishing scams, with Microsoft, Wells Fargo, and Google also being frequently targeted [[53](https://arxiv.org/html/2401.09727v1/#bib.bib53)]. This trend indicates a strategic shift in attackers’ preferences towards high-profile, globally recognized brands. Complementing this, Vade Secure’s Q3 2023 Phishing and Malware Report indicates a significant uptick in phishing activities, with a 104% increase in phishing URLs targeting Facebook and a staggering 973% increase in phishing URLs aimed at Bank of America, illustrating the financial sector’s increasing vulnerability [[54](https://arxiv.org/html/2401.09727v1/#bib.bib54)]. Further, Zscaler ThreatLabz’s 2023 Phishing Report observed a 47.2% surge in phishing attacks in 2022, with the education sector being particularly targeted, underscoring the diversification in industries at risk [[6](https://arxiv.org/html/2401.09727v1/#bib.bib6)]. Finally, Barracuda Networks, Inc.’s Spear Phishing: Top Threats and Trends Report 2022 delves into the nuanced tactics of spear phishing, showcasing the increasing sophistication and personalization of phishing attacks [[55](https://arxiv.org/html/2401.09727v1/#bib.bib55)].

There have been a handful of works over the years that analyze large scale phishing email campaigns, with real-world phishing adversaries targeting a larger number and diversity of targets [[56](https://arxiv.org/html/2401.09727v1/#bib.bib56)]. The work of Ho et al. [[14](https://arxiv.org/html/2401.09727v1/#bib.bib14)] focused primarily on the characterization of lateral phishing. Based on a massive dataset of 113 million employee-sent emails from 92 enterprise organizations, the study provided a detailed analysis of lateral phishing attacks. The researchers developed a classifier for detecting these attacks, and their findings shed light on the methods and behaviors of attackers. They discovered that most attackers rely on generic phishing content rather than crafting personalized attacks, indicating an opportunistic approach. Despite the lack of sophistication in content, these attacks were successful, with a significant percentage leading to the compromise of additional employee accounts. The work of Lain et al. [[15](https://arxiv.org/html/2401.09727v1/#bib.bib15)], researchers conducted a 15-month phishing experiment with over 14,000 participants in a company. The study aimed to understand employee vulnerability to phishing, assess the effectiveness of phishing warnings and training, and explore the potential of crowd-sourced phishing detection. Key findings revealed that email warnings were effective in reducing phishing susceptibility, and that employees can be used as a collective phishing detection mechanism. As opposed to the previous two studies, the work of Oest et al. [[16](https://arxiv.org/html/2401.09727v1/#bib.bib16)] focused on the detection and lifecycle of phishing email attacks. Their work proposed a framework that tracked the entire progression of phishing campaigns, from their online initiation to the compromise of accounts. Key findings include that the average phishing campaign lasts only 21 hours, with at least 7.42% of visitors surrendering their credentials and subsequently experiencing fraudulent transactions. A notable aspect was that a small subset of campaigns accounted for the majority of victims.

Recently, concerns around LLMs being used for adversarial purposes, particularly in the context of phishing attacks, have risen significantly. A recent report by Google Cloud underscores that LLMs can be used to create highly legitimate-seeming content, including voice and video, making it more challenging to identify misspellings, grammar errors, and cultural inaccuracies in phishing emails and messages [[57](https://arxiv.org/html/2401.09727v1/#bib.bib57)]. LLMs can also effectively translate and refine content, further complicating the detection of phishing attempts based on language use. The report points out that with generative AI, attackers can scale their operations and target a wide range of individuals with personalized and convincing emails, using data like names, organizations, job titles, and even health information. The work of Hazell et al. studied the effectiveness of LLMs toward creating realistic and cost-effective spear phishing emails to over 600 British Members of Parliament [[58](https://arxiv.org/html/2401.09727v1/#bib.bib58)]. Their work also notes the possibility of bypassing safeguards in LLMs through basic prompt engineering, and emphasize the need for robust governance measures to prevent misuse. Another recent study [[59](https://arxiv.org/html/2401.09727v1/#bib.bib59)] involved involved two groups of participants, exposed to either human-crafted or GPT-3 crafted phishing emails. Participants were asked to determine the authenticity of the emails, with feedback provided in the second round. The results indicated that human-crafted emails were more effective in deceiving people than those created by GPT-3, even after participants received training across various cognitive biases. Interestingly, participants felt more confident identifying phishing emails when they were human-crafted compared to those generated by GPT-3.

While the existing large-scale phishing studies provide comprehensive insights into traditional phishing techniques and organizational vulnerabilities, they notably overlook the emerging threat posed by LLMs in phishing. Studies like those by Ho et al. [[14](https://arxiv.org/html/2401.09727v1/#bib.bib14)], Lain et al. [[15](https://arxiv.org/html/2401.09727v1/#bib.bib15)], and Oest et al. [[16](https://arxiv.org/html/2401.09727v1/#bib.bib16)] offer valuable understanding of phishing campaign lifecycles, employee susceptibility, and detection mechanisms, yet they predate the rise of LLMs in cybersecurity threats. On the other hand, recent works focusing on LLM threats in phishing, such as those by Hazell et al. [[58](https://arxiv.org/html/2401.09727v1/#bib.bib58)] and Sharma et al. [[59](https://arxiv.org/html/2401.09727v1/#bib.bib59)], while crucial in highlighting the potential misuse of LLMs for crafting sophisticated phishing emails, do not explore these threats on a large scale. These studies primarily concentrate on the theoretical aspects and potential implications of LLMs in phishing, hypothesizing about their effectiveness in creating realistic and tailored phishing content. However, they fall short in empirically validating the actual impact of LLM-crafted phishing across organizations and in understanding how individuals within these organizations behave in response to such advanced attacks. This gap underscores a critical need in phishing research: to integrate the nuanced understanding of LLM threats into broader, organizational-scale studies to comprehensively assess the evolving landscape of phishing attacks.

## 7 Conclusion

This study represents a significant advancement in understanding the evolving landscape of cyber threats, particularly in the context of Large Language Models (LLMs) and their role in spear phishing attacks. Through a comprehensive 11-month investigation involving roughly 9000 employees at a large public university, we have uncovered critical insights into the efficacy and dangers posed by LLM-generated lateral spear phishing emails. Our findings highlight several key areas of concern and opportunities for improving cybersecurity measures in large organizations.

Our research revealed that a notable percentage of the university’s staff was vulnerable to these AI-crafted attacks, with around 10% of email recipients entering their login credentials in response to these sophisticated phishing attempts. This high success rate of LLM-generated emails underscores the need for heightened awareness and training regarding these new forms of cyber threats. Secondly, our study exposes the limitations of current anti-phishing infrastructures in detecting and preventing LLM-generated phishing attacks. We implemented a machine learning-based detection technique specifically tailored to identify LLM-generated phishing emails. With an F1-score of 98.96, this technique was shown to be effective, paving the way for its integration into existing cybersecurity frameworks. Finally, the insights gained from the university’s cyber operations team are invaluable. They highlight the critical need for updated training and educational approaches focusing on LLM phishing threats. The evolving nature of cyber threats demands a dynamic and responsive approach to cybersecurity education and training, ensuring that organizations and their employees are well-equipped to recognize and counter these sophisticated attacks.

## References

- [1] S. Gupta, A. Singhal, and A. Kapoor, “A literature survey on social engineering attacks: Phishing attack,” in *2016 international conference on computing, communication and automation (ICCCA)*. IEEE, 2016, pp. 537–540.
- [2] H. Aldawood and G. Skinner, “An academic review of current industrial and commercial cyber security social engineering solutions,” in *Proceedings of the 3rd International Conference on Cryptography, Security and Privacy*, 2019, pp. 110–115.
- [3] C. Hadnagy, *Social engineering: The art of human hacking*. John Wiley & Sons, 2010.
- [4] H. Aldawood and G. Skinner, “Educating and raising awareness on cyber security social engineering: A literature review,” in *2018 IEEE international conference on teaching, assessment, and learning for engineering (TALE)*. IEEE, 2018, pp. 62–68.
- [5] A. Das, S. Baki, A. El Aassal, R. Verma, and A. Dunbar, “Sok: a comprehensive reexamination of phishing research from the security perspective,” *IEEE Communications Surveys & Tutorials*, vol. 22, no. 1, pp. 671–708, 2019.
- [6] Z. ThreatLabz, “Zscaler threatlabz 2023 phishing report,” 2023.
- [7] A. Bhadane and S. B. Mane, “Detecting lateral spear phishing attacks in organisations,” *IET Information Security*, vol. 13, no. 2, pp. 133–140, 2019.
- [8] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale *et al.*, “Llama 2: Open foundation and fine-tuned chat models,” *arXiv preprint arXiv:2307.09288*, 2023.
- [9] Z. Zhao, S. Song, B. Duah, J. Macbeth, S. Carter, M. P. Van, N. S. Bravo, M. Klenk, K. Sick, and A. L. Filipowicz, “More human than human: Llm-generated narratives outperform human-llm interleaved narratives,” in *Proceedings of the 15th Conference on Creativity and Cognition*, 2023, pp. 368–370.
- [10] S. Herbold, A. Hautli-Janisz, U. Heuer, Z. Kikteva, and A. Trautsch, “A large-scale comparison of human-written versus chatgpt-generated essays,” *Scientific Reports*, vol. 13, no. 1, p. 18617, 2023.
- [11] B. Bloomberg, “Cisco sees ai software making phishing attacks harder to resist,” https://www.bnnbloomberg.ca/cisco-sees-ai-software-making-phishing-attacks-harder-to-resist-1.1911618, 2023, accessed: December 4, 2023.
- [12] Darktrace, “A ciso’s guide to email security,” accessed: December 4, 2023.
- [13] J. Wang, T. Herath, R. Chen, A. Vishwanath, and H. R. Rao, “Research article phishing susceptibility: An investigation into the processing of a targeted spear phishing email,” *IEEE transactions on professional communication*, vol. 55, no. 4, pp. 345–362, 2012.
- [14] G. Ho, A. Cidon, L. Gavish, M. Schweighauser, V. Paxson, S. Savage, G. M. Voelker, and D. Wagner, “Detecting and characterizing lateral phishing at scale,” in *28th USENIX Security Symposium (USENIX Security 19)*, 2019, pp. 1273–1290.
- [15] D. Lain, K. Kostiainen, and S. Čapkun, “Phishing in organizations: Findings from a large-scale and long-term study,” in *2022 IEEE Symposium on Security and Privacy (SP)*. IEEE, 2022, pp. 842–859.
- [16] A. Oest, P. Zhang, B. Wardman, E. Nunes, J. Burgis, A. Zand, K. Thomas, A. Doupé, and G.-J. Ahn, “Sunrise to sunset: Analyzing the end-to-end life cycle and effectiveness of phishing attacks at scale,” in *29th {USENIX} Security Symposium ({USENIX} Security 20)*, 2020.
- [17] A. Almomani, B. B. Gupta, S. Atawneh, A. Meulenberg, and E. Almomani, “A survey of phishing email filtering techniques,” *IEEE communications surveys & tutorials*, vol. 15, no. 4, pp. 2070–2090, 2013.
- [18] R. Alabdan, “Phishing attacks survey: Types, vectors, and technical approaches,” *Future internet*, vol. 12, no. 10, p. 168, 2020.
- [19] R. M. Mohammad, F. Thabtah, and L. McCluskey, “Intelligent rule-based phishing websites classification,” *IET Information Security*, vol. 8, no. 3, pp. 153–160, 2014.
- [20] S. Purkait, “Phishing counter measures and their effectiveness–literature review,” *Information Management & Computer Security*, vol. 20, no. 5, pp. 382–420, 2012.
- [21] N. Ayoobi, S. Shahriar, and A. Mukherjee, “The looming threat of fake and llm-generated linkedin profiles: Challenges and opportunities for detection and prevention,” in *Proceedings of the 34th ACM Conference on Hypertext and Social Media*, 2023, pp. 1–10.
- [22] K. Thomas, F. Li, A. Zand, J. Barrett, J. Ranieri, L. Invernizzi, Y. Markov, O. Comanescu, V. Eranti, A. Moscicki *et al.*, “Data breaches, phishing, or malware? understanding the risks of stolen credentials,” in *Proceedings of the 2017 ACM SIGSAC conference on computer and communications security*, 2017, pp. 1421–1434.
- [23] M. Bossetta, “The weaponization of social media: Spear phishing and cyberattacks on democracy,” *Journal of international affairs*, vol. 71, no. 1.5, pp. 97–106, 2018.
- [24] M. Silic and A. Back, “The dark side of social networking sites: Understanding phishing risks,” *Computers in Human Behavior*, vol. 60, pp. 35–43, 2016.
- [25] D. Hillman, Y. Harel, and E. Toch, “Evaluating organizational phishing awareness training on an enterprise scale,” *Computers & Security*, p. 103364, 2023.
- [26] E. Derner, K. Batistič, J. Zahálka, and R. Babuška, “A security risk taxonomy for large language models,” *arXiv preprint arXiv:2311.11415*, 2023.
- [27] B. Reinheimer, L. Aldag, P. Mayer, M. Mossano, R. Duezguen, B. Lofthouse, T. Von Landesberger, and M. Volkamer, “An investigation of phishing awareness and education over time: When and how to best remind users,” in *Sixteenth Symposium on Usable Privacy and Security (SOUPS 2020)*, 2020, pp. 259–284.
- [28] M. Steves, K. Greene, and M. Theofanos, “Categorizing human phishing difficulty: a phish scale,” *Journal of Cybersecurity*, vol. 6, no. 1, p. tyaa009, 2020.
- [29] B. Sabir, F. Ullah, M. A. Babar, and R. Gaire, “Machine learning for detecting data exfiltration: A review,” *ACM Computing Surveys (CSUR)*, vol. 54, no. 3, pp. 1–47, 2021.
- [30] F. Ullah, M. Edwards, R. Ramdhany, R. Chitchyan, M. A. Babar, and A. Rashid, “Data exfiltration: A review of external attack vectors and countermeasures,” *Journal of Network and Computer Applications*, vol. 101, pp. 18–54, 2018.
- [31] B. Tejaswi, N. Samarasinghe, S. Pourali, M. Mannan, and A. Youssef, “Leaky kits: The increased risk of data exposure from phishing kits,” in *2022 APWG Symposium on Electronic Crime Research (eCrime)*. IEEE, 2022, pp. 1–13.
- [32] S. Chakraborty, “Phishing email detection,” 2023. [Online]. Available: https://www.kaggle.com/dsv/6090437
- [33] “Vicuña 13b v1.5-16k,” Hugging Face Model Hub, 2023, available from: https://huggingface.co/lmsys/vicuna-13b-v1.5-16k [Accessed: 1st December 2023].
- [34] L. Zheng, W.-L. Chiang, Y. Sheng, S. Zhuang, Z. Wu, Y. Zhuang, Z. Lin, Z. Li, D. Li, E. Xing *et al.*, “Judging llm-as-a-judge with mt-bench and chatbot arena,” *arXiv preprint arXiv:2306.05685*, 2023.
- [35] S. Zhang, L. Dong, X. Li, S. Zhang, X. Sun, S. Wang, J. Li, R. Hu, T. Zhang, F. Wu *et al.*, “Instruction tuning for large language models: A survey,” *arXiv preprint arXiv:2308.10792*, 2023.
- [36] J. Pu, Z. Sarwar, S. M. Abdullah, A. Rehman, Y. Kim, P. Bhattacharya, M. Javed, and B. Viswanath, “Deepfake text detection: Limitations and opportunities,” in *2023 IEEE Symposium on Security and Privacy (SP)*. IEEE, 2023, pp. 1613–1630.
- [37] A. Gokaslan and V. Cohen, “Openwebtext corpus,” http://Skylion007.github.io/OpenWebTextCorpus, 2019.
- [38] R. Zellers, A. Holtzman, H. Rashkin, Y. Bisk, A. Farhadi, F. Roesner, and Y. Choi, “Defending against neural fake news,” *Advances in neural information processing systems*, vol. 32, 2019.
- [39] “google/flan-t5-xl,” https://huggingface.co/google/flan-t5-xl, 2023.
- [40] S. Yadav, B. Bohra *et al.*, “A review on recent phishing attacks in internet,” in *2015 International Conference on Green Computing and Internet of Things (ICGCIoT)*. IEEE, 2015, pp. 1312–1315.
- [41] D. Pienta, J. B. Thatcher, and A. Johnston, “Protecting a whale in a sea of phish,” *Journal of information technology*, vol. 35, no. 3, pp. 214–231, 2020.
- [42] A. Gusev, “Domestic private banking solutions can be quite successful as an effective protection against whaling-style cyber attacks which are used as a basis for more complex targeted phishing,” *Procedia Computer Science*, vol. 213, pp. 391–399, 2022.
- [43] B. Bowman, C. Laprade, Y. Ji, and H. H. Huang, “Detecting lateral movement in enterprise computer networks with unsupervised graph {AI},” in *23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020)*, 2020, pp. 257–268.
- [44] L. Nelson, R. Nairn, E. H. Chi, and G. Convertino, “Mail2tag: Augmenting email for sharing with implicit tag-based categorization,” in *2011 International Conference on Collaboration Technologies and Systems (CTS)*. IEEE, 2011, pp. 23–30.
- [45] Y. Koren, E. Liberty, Y. Maarek, and R. Sandler, “Automatically tagging email by leveraging other users’ folders,” in *Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining*, 2011, pp. 913–921.
- [46] H. Shahbaznezhad, F. Kolini, and M. Rashidirad, “Employees’ behavior in phishing attacks: what individual, organizational, and technological factors matter?” *Journal of Computer Information Systems*, vol. 61, no. 6, pp. 539–550, 2021.
- [47] M. Khonji, Y. Iraqi, and A. Jones, “Phishing detection: a literature survey,” *IEEE Communications Surveys & Tutorials*, vol. 15, no. 4, pp. 2091–2121, 2013.
- [48] Z. Alkhalil, C. Hewage, L. Nawaf, and I. Khan, “Phishing attacks: A recent comprehensive study and a new anatomy,” *Frontiers in Computer Science*, vol. 3, p. 563060, 2021.
- [49] R. Fatima, A. Yasin, L. Liu, and J. Wang, “How persuasive is a phishing email? a phishing game for phishing awareness,” *Journal of Computer Security*, vol. 27, no. 6, pp. 581–612, 2019.
- [50] M. Pattinson, C. Jerram, K. Parsons, A. McCormac, and M. Butavicius, “Why do some people manage phishing e-mails better than others?” *Information Management & Computer Security*, vol. 20, no. 1, pp. 18–28, 2012.
- [51] P. Rajivan and C. Gonzalez, “Creative persuasion: a study on adversarial behaviors and strategies in phishing attacks,” *Frontiers in psychology*, vol. 9, p. 135, 2018.
- [52] B. Parmar, “Protecting against spear-phishing,” *Computer Fraud & Security*, vol. 2012, no. 1, pp. 8–11, 2012.
- [53] Check Point Software Technologies Ltd., “Brand phishing report q3 2023,” https://www.checkpoint.com/press-releases/scammers-most-likely-to-impersonate-dhl-warns-new-brand-phishing-report/, September 2023.
- [54] V. Secure, “Vade secure q3 2023 phishing and malware report,” https://www.vadesecure.com/en/blog/q3-2023-phishing-malware-report, September 26 2023.
- [55] Barracuda Networks, Inc., “Spear phishing: Top threats and trends report 2022,” https://www.prnewswire.com/news-releases/new-spear-phishing-report-by-barracuda-shows-that-50-of-organizations-studied-were-victims-of-spear-phishing-in-2022-301832870.html, March 23 2022.
- [56] K. Parsons, A. McCormac, M. Pattinson, M. Butavicius, and C. Jerram, “The design of phishing studies: Challenges for researchers,” *Computers & Security*, vol. 52, pp. 194–206, 2015.
- [57] Google Cloud, “Google cloud cybersecurity forecast 2024,” Online, 2024. [Online]. Available: https://services.google.com/fh/files/misc/google-cloud-cybersecurity-forecast-2024.pdf
- [58] J. Hazell, “Large language models can be used to effectively scale spear phishing campaigns,” *arXiv preprint arXiv:2305.06972*, 2023.
- [59] M. Sharma, K. Singh, P. Aggarwal, and V. Dutt, “How well does gpt phish people? an investigation involving cognitive biases and feedback,” in *2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)*. IEEE, 2023, pp. 451–457.