# The growing threat of AI in social engineering: How business can mitigate risks

Created: June 29, 2024 6:55 PM
URL 1: https://www.fastcompany.com/91088574/the-growing-threat-of-ai-in-social-engineering-how-business-can-mitigate-risks

![https://images.fastcompany.com/image/upload/f_auto,c_fit,w_3840,q_auto/wp-cms-2/2024/04/influencer-marketing-how-to-target-gen-z-.jpg](https://images.fastcompany.com/image/upload/f_auto,c_fit,w_3840,q_auto/wp-cms-2/2024/04/influencer-marketing-how-to-target-gen-z-.jpg)

[Images: happy Wu / Adobe Stock]

Social engineering is by far the cyber industry’s most pervasive threat.

According to Verizon’s data breach report, a full three-quarters of data breaches in the last year ([74%](https://www.darkreading.com/threat-intelligence/verizon-dbir-social-engineering-breaches-spiraling-ransomware-costs)) involved the human element. In all likelihood, this number is much higher if one analyzes the root causes behind [online scams](https://www.pymnts.com/news/security-and-risk/2023/ftc-says-social-media-most-common-contact-method-for-scams/), [ransomware attacks](https://www.infosecurity-magazine.com/blogs/preventing-ransomware-with-cyber/), [credential theft](https://healthitsecurity.com/news/50-phishing-emails-seek-credential-theft-as-malware-delivery-declines), [MFA bypass](https://thehackernews.com/2024/02/4-ways-hackers-use-social-engineering.html), [RDP hijacking](https://www.csoonline.com/article/569621/rdp-hijacking-attacks-explained-and-how-to-mitigate-them.html), [APT attacks](https://www.recordedfuture.com/blog/social-engineering-remains-key-tradecraft-for-iranian-apts), and others. Cybercriminals amassed about [$50 billion](https://www.ic3.gov/Media/Y2023/PSA230609) from business email compromise (BEC) scams alone—a tiny fraction of social engineering fraud.

**WHAT IS GENERATIVE AI AND HOW DOES IT IMPACT SOCIAL ENGINEERING?**

Generative AI technology such as ChatGPT has extensive business use cases—it can write content, clean up text, conduct research, help identify target audiences, respond to emails, emulate a certain style of writing, and translate text, among myriad other things.

But what if threat actors abuse these capabilities to create highly convincing, targeted, and automated phishing messages at scale? This is exactly what’s happening. As soon as ChatGPT was launched, researchers reported more than a [1000% jump](https://www.cnbc.com/2023/11/28/ai-like-chatgpt-is-creating-huge-increase-in-malicious-phishing-email.html) in phishing emails.

**USE CASES OF GENERATIVE AI IN SOCIAL ENGINEERING**

GenAI has multiple use cases in social engineering. Listed below are some recent ones:

**1. Creating Highly Persuasive, Convincing, And Targeted Phishing Attacks**

Traditional phishing messages have some obvious red flags—they contain spelling errors, grammatical mistakes, or generic salutations. Some victims can detect phishing messages because they encounter an unfamiliar writing style, unusual timing, or unexpected mode of communication.

Everything changes with GenAI. Attackers can instruct AI to design messages that are grammatically perfect, mimic someone’s writing style, [spoof a voice](https://www.cnbc.com/2024/01/24/how-to-protect-yourself-against-ai-voice-cloning-scams.html#:~:text=In%20May%2C%20McAfee%20researchers%20found,changing%20the%20game%20for%20cybercriminals.), or generate a mock video.

**2. Using Deepfakes To Deceive And Dupe Targets**

[Deepfakes](https://www.fastcompany.com/90829233/deepfakes-get-ready-for-phishing-2-0) are nothing but synthetic audio, video, and images that are designed for deception. Remember how young the actor [Harrison Ford](https://www.allure.com/story/harrison-ford-looks-younger-indiana-jones-dial-of-destiny) looked in the latest Indiana Jones movie? This same technology is freely available on mobile phone apps for anyone to weaponize for malicious purposes.

Recently, a finance worker at a multinational firm was tricked into transferring [$25 million](https://edition.cnn.com/2024/02/04/asia/deepfake-cfo-scam-hong-kong-intl-hnk/index.html) to fraudsters. Initially, the victim was suspicious. However, on a video call, he recognized people who looked or sounded like his colleagues. [Similar incidents](https://www.straitstimes.com/asia/east-asia/china-scammer-uses-ai-to-impersonate-his-victim-s-friend-steal-820000) are happening worldwide, showing how AI is supercharging social engineering attacks.

**3. Conducting Reconnaissance And Building Target Lists**

AI can quickly assimilate and analyze large data sets on demographics, work histories, social media activity, health records, and [password leaks](https://sos-vo.org/news/billions-stolen-passwords-sale-dark-web). The resulting information is then used to build target personas based on specific demographics, occupations, interests, income range, and activity. Social engineers, state-sponsored threat actors, and [APT](https://www.recordedfuture.com/blog/social-engineering-remains-key-tradecraft-for-iranian-apts) (advanced persistent threat) actors can launch hyper-personalized social engineering and [misinformation](https://www.cnet.com/news/misinformation/ai-misinformation-how-it-works-and-ways-to-spot-it/) campaigns at scale.

**HOW CAN ORGANIZATIONS MITIGATE AI SOCIAL ENGINEERING?**

advertisement

Most social engineering attacks are difficult to detect. With AI thrown in the mix, social engineering attacks are set to become far more dangerous and deceptive.

Here are some best practices that can help organizations reduce AI social engineering risks.

**1. Develop Security Intuition In Employees**

Social engineering works on human manipulation—not technology manipulation. Therefore, the way to manage the social engineering problem lies in strengthening security instincts.

Using regular training, communications, [phishing simulation tests](https://www.gartner.com/reviews/market/security-awareness-computer-based-training/vendor/phishingbox/product/phishing-awareness-training/alternatives), and security best practices, organizations can train employees to follow their intuition to detect anomalies, develop awareness, and recognize a social engineering scam.

**2. Update Policies And Processes To Reflect AI Risks**

Have clear documentation, policies, and processes in place to remind and reinforce employees of the need to stay vigilant when online. Explain how AI is evolving and how it can be used to create phishing scripts. Specify the dos and don’ts (for example: pause and think before you click or reply), explain that they must always verify the authenticity of requests, especially when large transactions are involved. Report suspicious activity to security teams and define protocols in the event of a threat or breach.

**3. Leverage Advanced Cybersecurity Tools**

While social engineering attacks cannot alwaysbe stopped, they can certainly be blocked to a degree. Organizations can use [phishing-resistant MFA](https://www.cisa.gov/news-events/news/phishing-resistant-mfa-key-peace-mind) to block an attack, even when threat actors have access to user credentials. Adopt [zero trust](https://www.forbes.com/sites/forbesbusinesscouncil/2022/06/01/whats-zero-trust-and-whats-driving-its-adoption/) security to reduce risk of lateral movement. Security teams can deploy email authentication protocols like [SPF, DKIM, and DMARC](https://www.techtarget.com/searchsecurity/answer/Email-authentication-How-SPF-DKIM-and-DMARC-work-together) to block email spoofing attacks.

Organizations can also adopt AI-based cybersecurity controls that can analyze large data sets and detect social engineering attempts based on contextual information such as location, IP address, and identity. Password managers should be issued to employees to reduce risk of password [reuse](https://www.digitalinformationworld.com/2022/10/90-of-workers-reuse-passwords-despite.html). Security teams can also run [OSINT](https://www.forbes.com/sites/forbestechcouncil/2023/11/20/five-osint-tools-organizations-can-use-to-mitigate-social-engineering-attacks/) on the organization and its people to identify potential exposures.

AI social engineering is just getting started. Employers must make employees aware of these risks and train them to exercise their security intuition. In parallel, it’s also advisable to have multi-layered cybersecurity defenses in place so that even if one layer fails, the other can detect and block the threat. Always be prepared for the unexpected. In case of a security incident, both the organization and its employees must move quickly, without confusion, to mitigate the impact and recover from the attack.

*Stu Sjouwerman is the Founder and CEO of [KnowBe4 Inc.](https://www.knowbe4.com/), the world’s largest Security Awareness Training and Simulated Phishing platform.*

*Recognize your technological breakthrough by applying to this year’s [Next Big Things in Tech Awards](https://www.fastcompany.com/apply/next-big-things-in-tech) before the final deadline, July 12.
 Sign up for Next Big Things in Tech Awards notifications [here](https://events.fastcompany.com/2024nbtnotifications/register?ref=article).*